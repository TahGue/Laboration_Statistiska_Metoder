{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0d28504",
   "metadata": {},
   "source": [
    "# Linjär Regressionsanalys av Bostadspriser i Kalifornien\n",
    "\n",
    "## Introduktion\n",
    "\n",
    "I denna laboration undersöks sambandet mellan ett antal variabler som beskriver bostadsområden i Kalifornien och det medianbostadsvärde som observerats i respektive område. Datasetet, som härrör från folkräkningen 1990, innehåller 20 640 observationer och beskriver varje censusblock med uppgifter om bland annat medianinkomst, husålder, antal rum, befolkningsstorlek, geografisk position och närheten till havet.\n",
    "\n",
    "Responsvariabeln i analysen är `median_house_value`, det vill säga medianpriset på bostäder i ett givet block. Syftet är att med hjälp av multipel linjär regression (OLS) skatta hur de tillgängliga variablerna bidrar till att förklara prisvariationen, och att undersöka modellens styrkor och svagheter med statistiska verktyg: signifikanstest, konfidensintervall, Pearson-korrelation och residualdiagnostik."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9f60ed",
   "metadata": {},
   "source": [
    "## Upplägg\n",
    "\n",
    "Notebooken är strukturerad i tre modellsteg: en full modell för att identifiera multikollinearitet, en förbättrad modell med omkonstruerade särdrag för stabilare koefficienter, samt en log-linjär modell för att bättre uppfylla antaganden om residualvarians och residualfördelning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0607e146",
   "metadata": {},
   "source": [
    "## Metod\n",
    "\n",
    "Modellen implementeras i en egen klass (`LinearRegression` i `linear_regression.py`) som enbart använder numpy för linjär algebra och scipy.stats för fördelningar och test. Inga färdiga regressionsimplementationer eller visualiseringsbibliotek används.\n",
    "\n",
    "Arbetsgången börjar med att läsa in CSV-filen och konvertera alla värden till numeriska arrayer. Kolumnen `total_bedrooms` innehåller 207 saknade värden, vilka imputeras med kolumnens medelvärde för att bevara stickprovsstorleken. Eftersom datasetet innehåller flera censusblock med identiska koordinater aggregeras sedan observationerna per unik (longitude, latitude)-kombination: additiva variabler (`total_rooms`, `total_bedrooms`, `population`, `households`) summeras, medan nivåvariabler (`housing_median_age`, `median_income`, `median_house_value`) ersätts av medelvärdet inom gruppen. Dessutom tas alla observationer med `median_house_value` = 500 001 bort, eftersom detta värde utgör en artificiell cap som bryter mot OLS-antagandena.\n",
    "\n",
    "Den kategoriska variabeln `ocean_proximity` one-hot-kodas med referenskategorin `<1H OCEAN` utelämnad (drop-first) för att undvika linjärt beroende med interceptet.\n",
    "\n",
    "Analysen genomförs i tre steg. Först skattas en fullständig modell med samtliga originalvariabler för att identifiera multikollinearitet och andra problem. Därefter konstrueras en förbättrad modell där de starkt korrelerade blockstorlek-variablerna ersätts med kvotvariabler (`rooms_per_household`, `people_per_household`) och koordinaterna ersätts av ett enda avståndsmått (`distance_to_centroid`). Slutligen angrips det kvarvarande problemet — heteroskedasticitet och icke-normalfördelade residualer — genom en log-linjär modell: responsvariabeln log-transformeras och de numeriska särdragen z-standardiseras. Log-transformationen bygger på insikten att bostadspriser i grunden är multiplikativa — en procentuell felterm är mer realistisk än en absolut — och den gör OLS-antagandena mer rimliga.\n",
    "\n",
    "Koefficienterna skattas med normalequationen $\\hat{\\beta} = (X^TX)^{-1}X^Ty$. Implementationen använder `np.linalg.pinv` i stället för en vanlig invers, vilket innebär att beräkningen inte kraschar om $X^TX$ är singulär eller nära-singulär. Det är dock viktigt att förstå att pseudoinversen inte löser de statistiska problem som multikollinearitet medför — den ger enbart en numerisk lösning.\n",
    "\n",
    "Moore–Penrose-pseudoinversen möjliggör alltså skatten även när designmatrisen är rankbristig, men den reducerar inte den stora variansen som uppstår när prediktorerna nästan är linjärt beroende. Koefficienterna kan fortfarande få höga standardfel, breda konfidensintervall och instabila tecken. Därför är pseudoinversen en beräkningsmässig nödlösning snarare än en statistisk kur. För att hantera multikollinearitet krävs istället åtgärder såsom variabelselektion, regularisering eller dimensionsreduktion som faktiskt förändrar informationsinnehållet i designmatrisen.\n",
    "\n",
    "Efter skattningen utvärderas varje modell genom F-test och R² för övergripande signifikans, t-test och konfidensintervall för enskilda koefficienter, Pearson-korrelation för att identifiera multikollinearitet, samt residualstatistik för att bedöma modellens antaganden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ce57163",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T16:45:12.565133Z",
     "iopub.status.busy": "2026-02-13T16:45:12.565014Z",
     "iopub.status.idle": "2026-02-13T16:45:12.987168Z",
     "shell.execute_reply": "2026-02-13T16:45:12.986900Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "from scipy.stats import normaltest\n",
    "from linear_regression import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2b4109",
   "metadata": {},
   "source": [
    "## 1. Datainläsning och förbehandling\n",
    "\n",
    "Datasetet läses in från `housing.csv` med Pythons csv-modul. Varje rad representerar ett censusblock. De åtta numeriska kolumnerna konverteras till flyttal, och tomma celler tolkas som saknade värden (NaN). Dessa ersätts med respektive kolumns medelvärde.\n",
    "\n",
    "Eftersom datasetet innehåller flera block med identiska koordinater (samma longitud och latitud) aggregeras sedan observationerna per unik geografisk punkt: additiva variabler summeras och nivåvariabler medelvärderas. Därefter tas alla observationer bort där `median_house_value` är exakt 500 001, eftersom detta värde representerar en artificiell övre gräns i datasetet. Att behålla dessa censurerade observationer skulle systematiskt snedvrida modellens residualer i det övre prisintervallet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a9f8ce5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T16:45:12.988556Z",
     "iopub.status.busy": "2026-02-13T16:45:12.988440Z",
     "iopub.status.idle": "2026-02-13T16:45:13.214179Z",
     "shell.execute_reply": "2026-02-13T16:45:13.213896Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'observationer_ratt': 20640,\n",
       " 'saknade_varden_fore_imputering': {'total_bedrooms': 207},\n",
       " 'unika_koordinater': 12590,\n",
       " 'borttagna_cappade (y=500001)': 525,\n",
       " 'observationer_efter_rensning': 12065}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'housing.csv'\n",
    "with open(path, newline='', encoding='utf-8') as f:\n",
    "    r = csv.DictReader(f)\n",
    "    rows = list(r)\n",
    "cols_num = [\n",
    "    'longitude','latitude','housing_median_age','total_rooms','total_bedrooms',\n",
    "    'population','households','median_income'\n",
    "]\n",
    "y_col = 'median_house_value'\n",
    "cat_col = 'ocean_proximity'\n",
    "\n",
    "n_raw = len(rows)\n",
    "X_raw = np.empty((n_raw, len(cols_num)), dtype=float)\n",
    "y_raw = np.empty(n_raw, dtype=float)\n",
    "cat_raw = np.empty(n_raw, dtype=object)\n",
    "for i, row in enumerate(rows):\n",
    "    for j, c in enumerate(cols_num):\n",
    "        v = row[c]\n",
    "        X_raw[i, j] = float(v) if v != '' else np.nan\n",
    "    y_raw[i] = float(row[y_col])\n",
    "    cat_raw[i] = row[cat_col]\n",
    "\n",
    "missing_before = {c: int(np.isnan(X_raw[:, j]).sum()) for j, c in enumerate(cols_num)}\n",
    "\n",
    "col_means = np.nanmean(X_raw, axis=0)\n",
    "nan_inds = np.where(np.isnan(X_raw))\n",
    "X_raw[nan_inds] = np.take(col_means, nan_inds[1])\n",
    "\n",
    "sum_cols = {'total_rooms', 'total_bedrooms', 'population', 'households'}\n",
    "mean_cols = {'housing_median_age', 'median_income'}\n",
    "col_idx = {c: j for j, c in enumerate(cols_num)}\n",
    "\n",
    "groups = {}\n",
    "for i in range(n_raw):\n",
    "    key = (X_raw[i, col_idx['longitude']], X_raw[i, col_idx['latitude']])\n",
    "    if key not in groups:\n",
    "        groups[key] = []\n",
    "    groups[key].append(i)\n",
    "\n",
    "n_unique = len(groups)\n",
    "X_agg = np.empty((n_unique, len(cols_num)), dtype=float)\n",
    "y_agg = np.empty(n_unique, dtype=float)\n",
    "cat_agg = np.empty(n_unique, dtype=object)\n",
    "\n",
    "for g_idx, (key, indices) in enumerate(groups.items()):\n",
    "    idx_arr = np.array(indices)\n",
    "    for j, c in enumerate(cols_num):\n",
    "        if c in sum_cols:\n",
    "            X_agg[g_idx, j] = np.sum(X_raw[idx_arr, j])\n",
    "        elif c in mean_cols:\n",
    "            X_agg[g_idx, j] = np.mean(X_raw[idx_arr, j])\n",
    "        else:\n",
    "            X_agg[g_idx, j] = X_raw[idx_arr[0], j]\n",
    "    y_agg[g_idx] = np.mean(y_raw[idx_arr])\n",
    "    cat_agg[g_idx] = cat_raw[indices[0]]\n",
    "\n",
    "cap_mask = y_agg < 500001\n",
    "X_num = X_agg[cap_mask]\n",
    "y = y_agg[cap_mask]\n",
    "cat = cat_agg[cap_mask]\n",
    "n = len(y)\n",
    "\n",
    "{\n",
    "    'observationer_ratt': n_raw,\n",
    "    'saknade_varden_fore_imputering': {k: v for k, v in missing_before.items() if v > 0},\n",
    "    'unika_koordinater': n_unique,\n",
    "    'borttagna_cappade (y=500001)': int((~cap_mask).sum()),\n",
    "    'observationer_efter_rensning': n,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e451b60",
   "metadata": {},
   "source": [
    "## 2. Explorativ dataanalys (EDA)\n",
    "\n",
    "För att få en överblick av datasetet beräknas deskriptiv statistik (minimum, medelvärde, median, maximum och standardavvikelse) för samtliga numeriska variabler samt responsvariabeln. Dessutom undersöks fördelningen av den kategoriska variabeln `ocean_proximity`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33933b82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T16:45:13.215353Z",
     "iopub.status.busy": "2026-02-13T16:45:13.215289Z",
     "iopub.status.idle": "2026-02-13T16:45:13.221876Z",
     "shell.execute_reply": "2026-02-13T16:45:13.221664Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'deskriptiv_statistik': {'longitude': {'min': -124.35,\n",
       "   'medel': -119.68,\n",
       "   'median': -119.31,\n",
       "   'max': -114.31,\n",
       "   'std': 2.05},\n",
       "  'latitude': {'min': 32.54,\n",
       "   'medel': 35.93,\n",
       "   'median': 35.4,\n",
       "   'max': 41.95,\n",
       "   'std': 2.23},\n",
       "  'housing_median_age': {'min': 1.0,\n",
       "   'medel': 25.31,\n",
       "   'median': 25.0,\n",
       "   'max': 52.0,\n",
       "   'std': 11.51},\n",
       "  'total_rooms': {'min': 2.0,\n",
       "   'medel': 4332.53,\n",
       "   'median': 3458.0,\n",
       "   'max': 39320.0,\n",
       "   'std': 3409.05},\n",
       "  'total_bedrooms': {'min': 2.0,\n",
       "   'medel': 891.87,\n",
       "   'median': 678.0,\n",
       "   'max': 11493.0,\n",
       "   'std': 779.42},\n",
       "  'population': {'min': 5.0,\n",
       "   'medel': 2374.14,\n",
       "   'median': 1798.0,\n",
       "   'max': 35682.0,\n",
       "   'std': 2067.06},\n",
       "  'households': {'min': 2.0,\n",
       "   'medel': 828.39,\n",
       "   'median': 632.0,\n",
       "   'max': 10181.0,\n",
       "   'std': 728.21},\n",
       "  'median_income': {'min': 0.5,\n",
       "   'medel': 3.81,\n",
       "   'median': 3.58,\n",
       "   'max': 15.0,\n",
       "   'std': 1.6},\n",
       "  'median_house_value': {'min': 14999.0,\n",
       "   'medel': 188085.24,\n",
       "   'median': 167300.0,\n",
       "   'max': 500000.9,\n",
       "   'std': 100188.83}},\n",
       " 'ocean_proximity_fordelning': {'<1H OCEAN': 4429,\n",
       "  'INLAND': 5246,\n",
       "  'ISLAND': 5,\n",
       "  'NEAR BAY': 971,\n",
       "  'NEAR OCEAN': 1414}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_cols = cols_num + [y_col]\n",
    "all_data = np.column_stack([X_num, y])\n",
    "\n",
    "descriptive = {}\n",
    "for j, name in enumerate(all_cols):\n",
    "    col = all_data[:, j]\n",
    "    descriptive[name] = {\n",
    "        'min': round(float(np.min(col)), 2),\n",
    "        'medel': round(float(np.mean(col)), 2),\n",
    "        'median': round(float(np.median(col)), 2),\n",
    "        'max': round(float(np.max(col)), 2),\n",
    "        'std': round(float(np.std(col)), 2),\n",
    "    }\n",
    "\n",
    "ocean_categories, ocean_counts = np.unique(cat.astype(str), return_counts=True)\n",
    "kategori_fordelning = {str(c): int(cnt) for c, cnt in zip(ocean_categories, ocean_counts)}\n",
    "\n",
    "{\n",
    "    'deskriptiv_statistik': descriptive,\n",
    "    'ocean_proximity_fordelning': kategori_fordelning,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b916b4f",
   "metadata": {},
   "source": [
    "### Diskussion kring särdragsval\n",
    "\n",
    "Analysen genomförs i tre steg. I det första steget inkluderas samtliga tillgängliga numeriska variabler samt den kategoriska variabeln `ocean_proximity`. Detta görs medvetet för att kunna identifiera och studera multikollinearitet — fyra av variablerna (`total_rooms`, `total_bedrooms`, `population`, `households`) mäter alla blockstorlek och är därmed starkt korrelerade (Pearson-r mellan 0.86 och 0.97). Att inkludera samtliga gör det möjligt att visa hur korrelationsanalysen avslöjar dessa problem och vilka konsekvenser det får för signifikanstesterna.\n",
    "\n",
    "Inte alla parametrar är emellertid lämpliga att behålla i en regressionsmodell. Ett särdrag bör ingå endast om det tillför oberoende förklaringsinformation, är teoretiskt motiverat och inte introducerar överdriven multikollinearitet. Att inkludera starkt korrelerade variabler blåser upp koefficienternas varians och gör tolkningen svår. Samtidigt får inga variabler plockas bort enbart av bekvämlighet, eftersom det riskerar att skapa utelämnad variabel-bias. Parameterval måste därför balansera statistiska diagnoser mot domänkunskap om hur bostadspriser faktiskt bildas.\n",
    "\n",
    "I det andra steget konstrueras en förbättrad modell som adresserar de identifierade problemen. De fyra blockstorlek-variablerna ersätts med två kvotvariabler: `rooms_per_household` och `people_per_household`. Koordinaterna `longitude` och `latitude`, som också uppvisar stark korrelation (r ≈ −0.92), ersätts av ett enda avståndsmått — det euklidiska avståndet till datasetets geografiska centroid. Dessa transformationer minskar kollineariteten avsevärt och gör de kvarvarande koefficienterna stabilare och mer tolkbara.\n",
    "\n",
    "I det tredje steget log-transformeras responsvariabeln för att bättre matcha antagandet om jämn residualvarians och för att minska skevhet i feltermerna. Samtidigt z-standardiseras numeriska särdrag så att koefficienterna blir direkt jämförbara.\n",
    "\n",
    "Variabeln `ocean_proximity` one-hot-kodas med referenskategorin `<1H OCEAN` utelämnad (drop-first), vilket är nödvändigt för att undvika att dummy-variablerna bildar en linjärkombination med interceptet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7d34ed",
   "metadata": {},
   "source": [
    "## 3. Modellskattning\n",
    "\n",
    "Designmatrisen konstrueras genom att sammanfoga de åtta numeriska kolumnerna med de fyra dummy-variablerna från one-hot-kodningen (fem kategorier minus en referenskategori). Klassen lägger automatiskt till en kolumn med ettor för interceptet, vilket ger totalt 13 kolumner i designmatrisen och 12 skattade särdragskoefficienter utöver interceptet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3637690",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T16:45:13.223078Z",
     "iopub.status.busy": "2026-02-13T16:45:13.223006Z",
     "iopub.status.idle": "2026-02-13T16:45:13.229479Z",
     "shell.execute_reply": "2026-02-13T16:45:13.229273Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feature_names': ['longitude',\n",
       "  'latitude',\n",
       "  'housing_median_age',\n",
       "  'total_rooms',\n",
       "  'total_bedrooms',\n",
       "  'population',\n",
       "  'households',\n",
       "  'median_income',\n",
       "  'ocean_proximity=INLAND',\n",
       "  'ocean_proximity=ISLAND',\n",
       "  'ocean_proximity=NEAR BAY',\n",
       "  'ocean_proximity=NEAR OCEAN'],\n",
       " 'antal_sardrag (d)': 12,\n",
       " 'antal_observationer (n)': 12065}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearRegression(confidence_level=0.95, add_intercept=True, drop_first_category=True)\n",
    "X_cat, categories = model.one_hot_encode(cat, drop_first=model.drop_first_category)\n",
    "X = np.column_stack([X_num, X_cat])\n",
    "feature_names = cols_num + [f'{cat_col}={c}' for c in categories]\n",
    "model.fit(X, y, feature_names=feature_names)\n",
    "\n",
    "{\n",
    "    'feature_names': feature_names,\n",
    "    'antal_sardrag (d)': model.d,\n",
    "    'antal_observationer (n)': model.n,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0263d73a",
   "metadata": {},
   "source": [
    "## 4. Felmetrik\n",
    "\n",
    "De grundläggande felmåtten ger en uppfattning om hur stora avvikelser modellen producerar. Variansen $s^2$ är en väntevärdesriktig skattning av feltermens varians (med $n - d - 1$ i nämnaren), standardavvikelsen $s$ är dess kvadratrot, och RMSE beräknas som kvadratroten ur det genomsnittliga kvadratfelet. RMSE och $s$ ligger nära varandra här eftersom $n$ är stort relativt $d$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70e09f24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T16:45:13.230477Z",
     "iopub.status.busy": "2026-02-13T16:45:13.230417Z",
     "iopub.status.idle": "2026-02-13T16:45:13.232555Z",
     "shell.execute_reply": "2026-02-13T16:45:13.232351Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'varians (s²)': 3157411729.493205,\n",
       " 'standardavvikelse (s)': 56190.85094117373,\n",
       " 'RMSE': 56160.57004846399}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "    'varians (s²)': model.variance(),\n",
    "    'standardavvikelse (s)': model.standard_deviation(),\n",
    "    'RMSE': model.rmse(),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356adccd",
   "metadata": {},
   "source": [
    "## 5. Övergripande modellrelevans och signifikans\n",
    "\n",
    "F-testet prövar nollhypotesen att samtliga koefficienter (utom interceptet) är noll, det vill säga att ingen av de inkluderade variablerna bidrar till att förklara responsvariabeln. R² anger andelen av den totala variansen i Y som förklaras av regressionen. Justerat R² korrigerar för antalet parametrar och ger en mer rättvisande bild vid många särdrag, men i detta fall med $n \\approx 12\\,000$ och $d = 12$ är skillnaden försumbar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcbe5336",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T16:45:13.233618Z",
     "iopub.status.busy": "2026-02-13T16:45:13.233488Z",
     "iopub.status.idle": "2026-02-13T16:45:13.235963Z",
     "shell.execute_reply": "2026-02-13T16:45:13.235772Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'R²': 0.6857868302657955,\n",
       " 'justerat_R²': 0.6854739728116956,\n",
       " 'F-test': {'f_stat': 2192.0105187811623,\n",
       "  'df1': 12,\n",
       "  'df2': 12052,\n",
       "  'p_value': 0.0}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "    'R²': model.r2(),\n",
    "    'justerat_R²': model.adjusted_r2(),\n",
    "    'F-test': model.f_test(),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2af142",
   "metadata": {},
   "source": [
    "## 6. Individuella koefficienttest och konfidensintervall\n",
    "\n",
    "Tabellen nedan redovisar varje koefficients skattade värde, standardfel, t-statistika, p-värde och 95-procentigt konfidensintervall.\n",
    "\n",
    "Ett 95-procentigt konfidensintervall är den etablerade standarden i regressionsanalys och fungerar som en praktisk kompromiss mellan statistisk säkerhet och intervallprecision. En högre nivå, exempelvis 99%, skulle minska risken för typ-I-fel men samtidigt göra intervallen bredare och parameterinterpretationen mindre skarp. I detta fall räcker 95% för att uppnå hög tillförlitlighet, eftersom standardfelen redan är små tack vare stickprovsstorleken.\n",
    "\n",
    "I stora stickprov blir statistisk signifikans lätt att uppnå även för mycket små effekter — standardfelen krymper med $1/\\sqrt{n}$ — vilket innebär att nästan alla koefficienter förblir signifikanta även vid 99% konfidensnivå. Därför måste varje intervall tolkas tillsammans med koefficientens effektstorlek och den praktiska relevansen på bostadsmarknaden, inte enbart genom att konstatera om noll ligger utanför intervallet.\n",
    "\n",
    "Det är också avgörande att beakta multikollineariteten. T-testet för en enskild koefficient prövar om variabeln tillför förklaringskraft givet att alla andra prediktorer redan finns i modellen. När flera variabler mäter i stort sett samma fenomen (t.ex. `total_rooms`, `total_bedrooms`, `households` och `population`) delar de på informationen, vilket blåser upp standardfelen, breddar konfidensintervallen och gör t-testerna mindre tillförlitliga. En variabel kan då framstå som icke-signifikant, inte för att sambandet saknas, utan för att en närliggande variabel redan fångar samma variation. De fyra blockstorleksvariablerna bör därför tolkas som en grupp snarare än isolerat.\n",
    "\n",
    "En 95-procentig konfidensnivå är därmed lämplig eftersom den balanserar statistisk tillförlitlighet mot intervallprecision. En ännu högre nivå, såsom 99%, skulle visserligen reducera risken för typ-I-fel men producera bredare intervall och sämre tolkbarhet. Slutsatsen måste därför bygga på en samtidig värdering av (i) om noll ligger utanför intervallet, (ii) hur stor effekten är i praktiska termer och (iii) om sambandet är teoretiskt rimligt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ba2e088",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T16:45:13.237002Z",
     "iopub.status.busy": "2026-02-13T16:45:13.236938Z",
     "iopub.status.idle": "2026-02-13T16:45:13.239853Z",
     "shell.execute_reply": "2026-02-13T16:45:13.239672Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "============================= REGRESSION RESULTS =============================\n",
       "Observations: 12065           R-squared:      0.6858\n",
       "Features:     12              Adj. R-squared: 0.6855\n",
       "RMSE:         56160.5700      F-statistic:    2192.0105\n",
       "Res. Std Err: 56190.8509      Prob (F-stat):  0\n",
       "------------------------------------------------------------------------------\n",
       "                                   Coef    Std Err        t    P>|t| [95.0% Conf. Int.]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept *                  -1642064.4854 80856.4438   -20.31   0.0000 -1800556.1202 -1483572.8507\n",
       "longitude *                  -19314.8318   927.9813   -20.81   0.0000 -21133.8243 -17495.8393\n",
       "latitude *                   -17797.8615   900.3060   -19.77   0.0000 -19562.6060 -16033.1169\n",
       "housing_median_age *           746.7315    48.6491    15.35   0.0000 651.3715 842.0915\n",
       "total_rooms *                   -1.9464     0.4991    -3.90   0.0000  -2.9246  -0.9681\n",
       "total_bedrooms *                44.1500     4.6103     9.58   0.0000  35.1132  53.1869\n",
       "population *                   -19.3141     0.6740   -28.66   0.0000 -20.6352 -17.9930\n",
       "households *                    25.1487     5.1742     4.86   0.0000  15.0066  35.2909\n",
       "median_income *              39352.1700   419.6494    93.77   0.0000 38529.5896 40174.7504\n",
       "ocean_proximity=INLAND *     -39750.5076  1714.2530   -23.19   0.0000 -43110.7192 -36390.2960\n",
       "ocean_proximity=ISLAND *     181007.4475 25187.4132     7.19   0.0000 131636.0665 230378.8285\n",
       "ocean_proximity=NEAR BAY *   -9147.2717  2209.4739    -4.14   0.0000 -13478.1960 -4816.3474\n",
       "ocean_proximity=NEAR OCEAN * 10258.2292  1772.7053     5.79   0.0000 6783.4417 13733.0167\n",
       "==============================================================================\n",
       "* p<0.0001, . p<0.05"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5619af8e",
   "metadata": {},
   "source": [
    "## 7. Beroendeanalys (Pearson-korrelation)\n",
    "\n",
    "Pearson-korrelationskoefficienten mäter styrkan i det linjära sambandet mellan två variabler. Värden nära ±1 innebär att variablerna i praktiken bär samma information, vilket är problematiskt i en regressionsmodell: om två prediktorer är nästan linjärkombinationer av varandra kan OLS inte på ett meningsfullt sätt avgöra vilken av dem som \"orsakar\" variationen i Y. Nedan beräknas korrelationsmatrisen för samtliga särdrag i designmatrisen, exklusive interceptet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "543d64c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T16:45:13.240784Z",
     "iopub.status.busy": "2026-02-13T16:45:13.240730Z",
     "iopub.status.idle": "2026-02-13T16:45:13.252726Z",
     "shell.execute_reply": "2026-02-13T16:45:13.252523Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'korrelationsmatris': [[1.0,\n",
       "   -0.91,\n",
       "   -0.1,\n",
       "   0.11,\n",
       "   0.12,\n",
       "   0.15,\n",
       "   0.11,\n",
       "   0.03,\n",
       "   -0.03,\n",
       "   0.01,\n",
       "   -0.37,\n",
       "   0.02],\n",
       "  [-0.91,\n",
       "   1.0,\n",
       "   0.01,\n",
       "   -0.19,\n",
       "   -0.2,\n",
       "   -0.24,\n",
       "   -0.2,\n",
       "   -0.15,\n",
       "   0.34,\n",
       "   -0.02,\n",
       "   0.25,\n",
       "   -0.16],\n",
       "  [-0.1, 0.01, 1.0, -0.03, 0.05, 0.06, 0.07, -0.19, -0.19, 0.03, 0.19, 0.05],\n",
       "  [0.11, -0.19, -0.03, 1.0, 0.93, 0.86, 0.93, 0.16, -0.24, -0.02, 0.11, 0.02],\n",
       "  [0.12, -0.2, 0.05, 0.93, 1.0, 0.9, 0.99, -0.03, -0.25, -0.01, 0.11, 0.03],\n",
       "  [0.15, -0.24, 0.06, 0.86, 0.9, 1.0, 0.92, -0.02, -0.27, -0.02, 0.06, 0.01],\n",
       "  [0.11, -0.2, 0.07, 0.93, 0.99, 0.92, 1.0, -0.01, -0.28, -0.02, 0.11, 0.03],\n",
       "  [0.03,\n",
       "   -0.15,\n",
       "   -0.19,\n",
       "   0.16,\n",
       "   -0.03,\n",
       "   -0.02,\n",
       "   -0.01,\n",
       "   1.0,\n",
       "   -0.32,\n",
       "   -0.01,\n",
       "   0.1,\n",
       "   0.03],\n",
       "  [-0.03,\n",
       "   0.34,\n",
       "   -0.19,\n",
       "   -0.24,\n",
       "   -0.25,\n",
       "   -0.27,\n",
       "   -0.28,\n",
       "   -0.32,\n",
       "   1.0,\n",
       "   -0.02,\n",
       "   -0.26,\n",
       "   -0.32],\n",
       "  [0.01,\n",
       "   -0.02,\n",
       "   0.03,\n",
       "   -0.02,\n",
       "   -0.01,\n",
       "   -0.02,\n",
       "   -0.02,\n",
       "   -0.01,\n",
       "   -0.02,\n",
       "   1.0,\n",
       "   -0.01,\n",
       "   -0.01],\n",
       "  [-0.37, 0.25, 0.19, 0.11, 0.11, 0.06, 0.11, 0.1, -0.26, -0.01, 1.0, -0.11],\n",
       "  [0.02, -0.16, 0.05, 0.02, 0.03, 0.01, 0.03, 0.03, -0.32, -0.01, -0.11, 1.0]],\n",
       " 'legend': {0: 'longitude',\n",
       "  1: 'latitude',\n",
       "  2: 'housing_median_age',\n",
       "  3: 'total_rooms',\n",
       "  4: 'total_bedrooms',\n",
       "  5: 'population',\n",
       "  6: 'households',\n",
       "  7: 'median_income',\n",
       "  8: 'ocean_proximity=INLAND',\n",
       "  9: 'ocean_proximity=ISLAND',\n",
       "  10: 'ocean_proximity=NEAR BAY',\n",
       "  11: 'ocean_proximity=NEAR OCEAN'},\n",
       " 'starka_korrelationer (|r| > 0.8)': {'longitude <-> latitude': -0.911,\n",
       "  'total_rooms <-> total_bedrooms': 0.931,\n",
       "  'total_rooms <-> population': 0.863,\n",
       "  'total_rooms <-> households': 0.926,\n",
       "  'total_bedrooms <-> population': 0.904,\n",
       "  'total_bedrooms <-> households': 0.987,\n",
       "  'population <-> households': 0.924}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearson = model.pearson_pairs(X, include_intercept=False)\n",
    "r_matrix = pearson['r']\n",
    "\n",
    "n_feats = len(feature_names)\n",
    "starka_korrelationer = {}\n",
    "for i in range(n_feats):\n",
    "    for j in range(i + 1, n_feats):\n",
    "        if abs(r_matrix[i, j]) > 0.8:\n",
    "            starka_korrelationer[f'{feature_names[i]} <-> {feature_names[j]}'] = float(np.round(r_matrix[i, j], 3))\n",
    "\n",
    "{\n",
    "    'korrelationsmatris': np.round(r_matrix, 2).tolist(),\n",
    "    'legend': {i: name for i, name in enumerate(feature_names)},\n",
    "    'starka_korrelationer (|r| > 0.8)': starka_korrelationer,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce99e77",
   "metadata": {},
   "source": [
    "### Tolkning av korrelationsmatrisen\n",
    "\n",
    "Den mest påfallande strukturen i korrelationsmatrisen är det starka linjära beroendet mellan de fyra blockstorlek-variablerna: `total_rooms`, `total_bedrooms`, `households` och `population` uppvisar parvis Pearson-r mellan 0.86 och 0.97. Det extremaste paret är `total_bedrooms` och `households` med r = 0.975, vilket innebär att ungefär 95% av variansen i den ena variabeln redan förklaras av den andra. Att inkludera båda i samma regression ger därför mycket lite extra information, men kostar i form av uppblåsta standardfel och instabila koefficienter.\n",
    "\n",
    "Konsekvensen för signifikanstesterna är konkret: t-testet för en enskild koefficient mäter om variabeln tillför förklaringskraft utöver det som de övriga variablerna redan fångar. När två variabler mäter i princip samma sak delar de på denna förklaringskraft, och båda kan få onödigt höga standardfel. I värsta fall kan en genuint viktig variabel framstå som icke-signifikant, enbart för att en snarlikt korrelerad variabel redan finns i modellen. Koefficienternas storlek och till och med tecken kan dessutom ändras drastiskt om en av de korrelerade variablerna tas bort — ett tydligt tecken på att de individuella skattningarna inte är stabila. I denna modell har de fyra blockstorlek-variablerna ändå samtliga signifikanta p-värden, men det beror sannolikt på det mycket stora stickprovet snarare än på att modellen kan separera deras individuella bidrag.\n",
    "\n",
    "Severe multikollinearitet snedvrider inte OLS-koefficienterna i sig, men den blåser upp deras varians (motsvarande höga variance inflation factors), vilket leder till tre följder: (1) standardfelen växer och t-tester får lägre styrka, (2) konfidensintervallen blir bredare och mindre informativa, och (3) koefficienternas tecken kan bli instabila om modellen specificeras om. Den centrala problemlinjen är alltså: multikollinearitet → högre koefficientvarians → större standardfel → bredare konfidensintervall → svagare t-test → sämre tolkbarhet.\n",
    "\n",
    "Koordinaterna `longitude` och `latitude` har r ≈ −0.92, vilket är förväntat givet Kaliforniens geografi (kusten löper ungefär nordväst–sydost). Även här bör koefficienterna tolkas tillsammans snarare än var för sig.\n",
    "\n",
    "Variabeln `median_income` uppvisar däremot låg korrelation med samtliga övriga prediktorer (|r| < 0.25) och är därmed det mest oberoende särdraget i modellen. Dess koefficient och signifikanstest är följaktligen de mest tillförlitliga."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3069beaa",
   "metadata": {},
   "source": [
    "## 8. Jämförelse av konfidensnivåer (95% vs 99%)\n",
    "\n",
    "Som diskuterades ovan är valet av konfidensnivå inte trivialt vid stora stickprov. Nedan visas samma modell med 99-procentiga konfidensintervall. Intervallen breddas — det kritiska t-värdet ökar från ca 1.96 till ca 2.58 — men i denna modell förblir samtliga koefficienter signifikanta vid 99% också. Att resultaten knappt förändras illustrerar att med cirka 12 000 observationer har testerna mycket hög statistisk kraft och att valet mellan 95% och 99% i detta fall inte ger kvalitativt annorlunda slutsatser. En mer meningsfull distinktion vore att jämföra konfidensintervallens bredd med koefficienternas praktiska tolkningsbarhet, snarare än att enbart titta på om p-värdet passerar en viss tröskel. I avsnitt 12 prövas därför en konfidensnivå anpassad till modellens faktiska förklaringsgrad.\n",
    "\n",
    "I stora stickprov innebär statistisk signifikans inte automatiskt att effekten är praktiskt viktig. Mycket små effekter kan bli signifikanta när standardfelen krymper, och man riskerar då att övertolka obetydliga förändringar. Därför måste konfidensintervall alltid värderas både ur statistiskt (om noll exkluderas) och praktiskt (om intervallet rymmer en meningsfull effektstorlek) perspektiv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca11e97e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T16:45:13.253816Z",
     "iopub.status.busy": "2026-02-13T16:45:13.253752Z",
     "iopub.status.idle": "2026-02-13T16:45:13.256961Z",
     "shell.execute_reply": "2026-02-13T16:45:13.256756Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "============================= REGRESSION RESULTS =============================\n",
       "Observations: 12065           R-squared:      0.6858\n",
       "Features:     12              Adj. R-squared: 0.6855\n",
       "RMSE:         56160.5700      F-statistic:    2192.0105\n",
       "Res. Std Err: 56190.8509      Prob (F-stat):  0\n",
       "------------------------------------------------------------------------------\n",
       "                                   Coef    Std Err        t    P>|t| [99.0% Conf. Int.]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept *                  -1642064.4854 80856.4438   -20.31   0.0000 -1850369.8726 -1433759.0983\n",
       "longitude *                  -19314.8318   927.9813   -20.81   0.0000 -21705.5317 -16924.1318\n",
       "latitude *                   -17797.8615   900.3060   -19.77   0.0000 -20117.2633 -15478.4596\n",
       "housing_median_age *           746.7315    48.6491    15.35   0.0000 621.3999 872.0631\n",
       "total_rooms *                   -1.9464     0.4991    -3.90   0.0000  -3.2321  -0.6607\n",
       "total_bedrooms *                44.1500     4.6103     9.58   0.0000  32.2729  56.0271\n",
       "population *                   -19.3141     0.6740   -28.66   0.0000 -21.0504 -17.5778\n",
       "households *                    25.1487     5.1742     4.86   0.0000  11.8189  38.4786\n",
       "median_income *              39352.1700   419.6494    93.77   0.0000 38271.0535 40433.2865\n",
       "ocean_proximity=INLAND *     -39750.5076  1714.2530   -23.19   0.0000 -44166.8302 -35334.1851\n",
       "ocean_proximity=ISLAND *     181007.4475 25187.4132     7.19   0.0000 116118.6939 245896.2010\n",
       "ocean_proximity=NEAR BAY *   -9147.2717  2209.4739    -4.14   0.0000 -14839.4010 -3455.1425\n",
       "ocean_proximity=NEAR OCEAN * 10258.2292  1772.7053     5.79   0.0000 5691.3197 14825.1387\n",
       "==============================================================================\n",
       "* p<0.0001, . p<0.05"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_99 = LinearRegression(confidence_level=0.99, add_intercept=True, drop_first_category=True)\n",
    "model_99.fit(X, y, feature_names=feature_names)\n",
    "\n",
    "model_99.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78eef3c1",
   "metadata": {},
   "source": [
    "## 9. Predikterade vs. Faktiska värden\n",
    "\n",
    "För att bedöma modellens träffsäkerhet jämförs de predikterade värdena med de faktiska. Nedan delas observationerna upp i prisintervall, och för varje intervall redovisas medelresidual och residualernas standardavvikelse. Om modellen vore perfekt skulle medelresidualen vara noll i varje intervall. Avvikelser visar i vilka prisklasser modellen systematiskt över- eller underskattar.\n",
    "\n",
    "I stora stickprov innebär statistisk signifikans inte automatiskt att effekten är praktiskt viktig. Mycket små effekter kan bli statistiskt signifikanta när standardfelen krymper. Därför måste konfidensintervallen bedömas med både statistisk och praktisk betydelse i åtanke."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2706a529",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T16:45:13.257856Z",
     "iopub.status.busy": "2026-02-13T16:45:13.257801Z",
     "iopub.status.idle": "2026-02-13T16:45:13.261339Z",
     "shell.execute_reply": "2026-02-13T16:45:13.261136Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prediktionssammanfattning': {'medel_predikterat': 188085.24,\n",
       "  'medel_faktiskt': 188085.24,\n",
       "  'korrelation_pred_vs_faktiskt': 0.8281},\n",
       " 'residualer_per_prisintervall': {'0-100k': {'antal': 2560,\n",
       "   'medel_residual': -22130.56,\n",
       "   'std_residual': 34396.23},\n",
       "  '100k-200k': {'antal': 4890,\n",
       "   'medel_residual': -17103.12,\n",
       "   'std_residual': 43789.57},\n",
       "  '200k-300k': {'antal': 2870,\n",
       "   'medel_residual': 4182.71,\n",
       "   'std_residual': 44409.02},\n",
       "  '300k-400k': {'antal': 1222,\n",
       "   'medel_residual': 56032.73,\n",
       "   'std_residual': 54989.08},\n",
       "  '400k-500k': {'antal': 523,\n",
       "   'medel_residual': 114363.54,\n",
       "   'std_residual': 74221.11}}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X)\n",
    "residuals = model.residuals()\n",
    "\n",
    "bins = [0, 100000, 200000, 300000, 400000, 500001, np.inf]\n",
    "labels = ['0-100k', '100k-200k', '200k-300k', '300k-400k', '400k-500k', '500k+']\n",
    "pred_vs_actual = {}\n",
    "for k in range(len(bins) - 1):\n",
    "    mask = (y >= bins[k]) & (y < bins[k + 1])\n",
    "    if mask.sum() > 0:\n",
    "        errors = residuals[mask]\n",
    "        pred_vs_actual[labels[k]] = {\n",
    "            'antal': int(mask.sum()),\n",
    "            'medel_residual': round(float(np.mean(errors)), 2),\n",
    "            'std_residual': round(float(np.std(errors)), 2),\n",
    "        }\n",
    "\n",
    "{\n",
    "    'prediktionssammanfattning': {\n",
    "        'medel_predikterat': round(float(np.mean(y_pred)), 2),\n",
    "        'medel_faktiskt': round(float(np.mean(y)), 2),\n",
    "        'korrelation_pred_vs_faktiskt': round(float(np.corrcoef(y, y_pred)[0, 1]), 4),\n",
    "    },\n",
    "    'residualer_per_prisintervall': pred_vs_actual,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a796e4d",
   "metadata": {},
   "source": [
    "## 10. Residualdiagnostik\n",
    "\n",
    "OLS bygger på antagandet att feltermerna är oberoende, har konstant varians (homoskedasticitet) och är approximativt normalfördelade. Om dessa antaganden inte håller kan de beräknade standardfelen och därmed alla signifikanstest och konfidensintervall bli missvisande. Nedan undersöks residualernas fördelning numeriskt: kvartiler, skevhet, kurtosis, ett formellt normalitetstest (D'Agostino–Pearson) samt en enkel jämförelse av residualspridningen vid låga respektive höga predikterade värden som indikation på heteroskedasticitet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec532c9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T16:45:13.262352Z",
     "iopub.status.busy": "2026-02-13T16:45:13.262293Z",
     "iopub.status.idle": "2026-02-13T16:45:13.266251Z",
     "shell.execute_reply": "2026-02-13T16:45:13.266063Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'residualer': {'medelvarde': 0.0,\n",
       "  'std': 56160.57,\n",
       "  'min': -542916.15,\n",
       "  'Q1': -34661.1,\n",
       "  'median': -7393.26,\n",
       "  'Q3': 25877.66,\n",
       "  'max': 395767.12,\n",
       "  'skevhet': 0.9684,\n",
       "  'kurtosis': 4.1144},\n",
       " 'normalitetstest (DAgostino-Pearson)': {'p_varde': 0.0,\n",
       "  'normalfordelat': False},\n",
       " 'heteroskedasticitet_indikation': {'std_laga_prediktioner': 47364.76,\n",
       "  'std_hoga_prediktioner': 63753.01,\n",
       "  'kvot': 1.346}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "residuals = model.residuals()\n",
    "\n",
    "quartiles = np.percentile(residuals, [0, 25, 50, 75, 100])\n",
    "\n",
    "_, normaltest_p = normaltest(residuals)\n",
    "\n",
    "low_pred = y_pred < np.median(y_pred)\n",
    "high_pred = ~low_pred\n",
    "std_low = float(np.std(residuals[low_pred]))\n",
    "std_high = float(np.std(residuals[high_pred]))\n",
    "\n",
    "{\n",
    "    'residualer': {\n",
    "        'medelvarde': round(float(np.mean(residuals)), 4),\n",
    "        'std': round(float(np.std(residuals)), 2),\n",
    "        'min': round(float(quartiles[0]), 2),\n",
    "        'Q1': round(float(quartiles[1]), 2),\n",
    "        'median': round(float(quartiles[2]), 2),\n",
    "        'Q3': round(float(quartiles[3]), 2),\n",
    "        'max': round(float(quartiles[4]), 2),\n",
    "        'skevhet': round(float(np.mean((residuals - np.mean(residuals))**3) / np.std(residuals)**3), 4),\n",
    "        'kurtosis': round(float(np.mean((residuals - np.mean(residuals))**4) / np.std(residuals)**4 - 3), 4),\n",
    "    },\n",
    "    'normalitetstest (DAgostino-Pearson)': {\n",
    "        'p_varde': float(normaltest_p),\n",
    "        'normalfordelat': bool(normaltest_p > 0.05),\n",
    "    },\n",
    "    'heteroskedasticitet_indikation': {\n",
    "        'std_laga_prediktioner': round(std_low, 2),\n",
    "        'std_hoga_prediktioner': round(std_high, 2),\n",
    "        'kvot': round(std_high / std_low, 3),\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f947d24f",
   "metadata": {},
   "source": [
    "## 11. Sammanfattning av den första modellen\n",
    "\n",
    "Den första modellen, med samtliga originalvariabler, ger en förklaringsgrad på R² ≈ 0.686 och ett F-test med p ≈ 0, vilket innebär att modellen som helhet är starkt signifikant. Variabeln `median_income` dominerar med t ≈ 94 och är den mest stabila koefficienten tack vare sin låga korrelation med övriga prediktorer.\n",
    "\n",
    "Korrelationsanalysen avslöjar dock allvarlig multikollinearitet: de fyra blockstorlek-variablerna (`total_rooms`, `total_bedrooms`, `population`, `households`) har parvis Pearson-r mellan 0.86 och 0.99, och koordinaterna `longitude`/`latitude` har r ≈ −0.91. Detta innebär att de individuella koefficienterna för dessa variabler inte är stabila — deras storlek och tecken kan ändras om modellspecifikationen ändras. Att samtliga ändå uppvisar signifikanta p-värden beror sannolikt på det stora stickprovet snarare än på att modellen kan separera deras individuella bidrag.\n",
    "\n",
    "Residualanalysen visar heteroskedasticitet (kvot hög/låg std ≈ 1.35) och icke-normalfördelade residualer (skevhet ≈ 0.97, excess kurtosis ≈ 4.1). Dessa avvikelser innebär att standardfel, p-värden och konfidensintervall inte fullt ut kan litas på.\n",
    "\n",
    "Sammantaget motiverar dessa insikter en förbättrad modellspecifikation, vilken presenteras i nästa avsnitt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e94874",
   "metadata": {},
   "source": [
    "## 12. Förbättrad modell — reducerad multikollinearitet\n",
    "\n",
    "För att adressera de problem som identifierades i den första modellen konstrueras en ny särdragsuppsättning. De fyra blockstorlek-variablerna (`total_rooms`, `total_bedrooms`, `population`, `households`) ersätts med två kvotvariabler: `rooms_per_household` (antal rum per hushåll) och `people_per_household` (antal personer per hushåll). Dessa fångar samma strukturella information men är betydligt mindre korrelerade med varandra. Variabeln `total_bedrooms` tas bort helt eftersom dess effekt i princip redan fångas av de nya kvotvariablerna, och den var dessutom den enda kolumnen med saknade värden.\n",
    "\n",
    "Koordinaterna `longitude` och `latitude`, som uppvisade r ≈ −0.91, ersätts av ett enda mått: `distance_to_centroid`, det euklidiska avståndet från varje punkt till datasetets geografiska medelpunkt. Detta komprimerar den geografiska informationen till en enda dimension utan att förlora den huvudsakliga variationen — avstånd från centrum av Kaliforniens bostadsbestånd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "737db485",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T16:45:13.267413Z",
     "iopub.status.busy": "2026-02-13T16:45:13.267349Z",
     "iopub.status.idle": "2026-02-13T16:45:13.273919Z",
     "shell.execute_reply": "2026-02-13T16:45:13.273718Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feature_names': ['distance_to_centroid',\n",
       "  'housing_median_age',\n",
       "  'median_income',\n",
       "  'rooms_per_household',\n",
       "  'people_per_household',\n",
       "  'ocean_proximity=INLAND',\n",
       "  'ocean_proximity=ISLAND',\n",
       "  'ocean_proximity=NEAR BAY',\n",
       "  'ocean_proximity=NEAR OCEAN'],\n",
       " 'antal_sardrag (d)': 9,\n",
       " 'antal_observationer (n)': 12065}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lon_idx = col_idx['longitude']\n",
    "lat_idx = col_idx['latitude']\n",
    "centroid_lon = np.mean(X_num[:, lon_idx])\n",
    "centroid_lat = np.mean(X_num[:, lat_idx])\n",
    "distance_to_centroid = np.sqrt(\n",
    "    (X_num[:, lon_idx] - centroid_lon)**2 + (X_num[:, lat_idx] - centroid_lat)**2\n",
    ")\n",
    "\n",
    "rooms_per_household = X_num[:, col_idx['total_rooms']] / X_num[:, col_idx['households']]\n",
    "people_per_household = X_num[:, col_idx['population']] / X_num[:, col_idx['households']]\n",
    "\n",
    "X_num_2 = np.column_stack([\n",
    "    distance_to_centroid,\n",
    "    X_num[:, col_idx['housing_median_age']],\n",
    "    X_num[:, col_idx['median_income']],\n",
    "    rooms_per_household,\n",
    "    people_per_household,\n",
    "])\n",
    "\n",
    "feature_names_2 = [\n",
    "    'distance_to_centroid',\n",
    "    'housing_median_age',\n",
    "    'median_income',\n",
    "    'rooms_per_household',\n",
    "    'people_per_household',\n",
    "]\n",
    "\n",
    "X_cat_2, categories_2 = LinearRegression.one_hot_encode(cat, drop_first=True)\n",
    "X2 = np.column_stack([X_num_2, X_cat_2])\n",
    "feature_names_2 = feature_names_2 + [f'{cat_col}={c}' for c in categories_2]\n",
    "\n",
    "model_2 = LinearRegression(confidence_level=0.95, add_intercept=True, drop_first_category=True)\n",
    "model_2.fit(X2, y, feature_names=feature_names_2)\n",
    "\n",
    "{\n",
    "    'feature_names': feature_names_2,\n",
    "    'antal_sardrag (d)': model_2.d,\n",
    "    'antal_observationer (n)': model_2.n,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "108d7e1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T16:45:13.274895Z",
     "iopub.status.busy": "2026-02-13T16:45:13.274814Z",
     "iopub.status.idle": "2026-02-13T16:45:13.278010Z",
     "shell.execute_reply": "2026-02-13T16:45:13.277810Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "============================= REGRESSION RESULTS =============================\n",
       "Observations: 12065           R-squared:      0.6435\n",
       "Features:     9               Adj. R-squared: 0.6433\n",
       "RMSE:         59818.1433      F-statistic:    2418.0425\n",
       "Res. Std Err: 59842.9486      Prob (F-stat):  0\n",
       "------------------------------------------------------------------------------\n",
       "                                   Coef    Std Err        t    P>|t| [95.0% Conf. Int.]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept *                  55452.9497  3115.5322    17.80   0.0000 49346.0056 61559.8937\n",
       "distance_to_centroid *       -4700.7219   519.8062    -9.04   0.0000 -5719.6256 -3681.8183\n",
       "housing_median_age *           812.8372    51.2368    15.86   0.0000 712.4048 913.2696\n",
       "median_income *              38651.7574   393.2437    98.29   0.0000 37880.9366 39422.5782\n",
       "rooms_per_household .          572.0198   214.3836     2.67   0.0076 151.7934 992.2462\n",
       "people_per_household *        -244.1889    40.2767    -6.06   0.0000 -323.1377 -165.2401\n",
       "ocean_proximity=INLAND *     -64198.8352  1349.4731   -47.57   0.0000 -66844.0195 -61553.6508\n",
       "ocean_proximity=ISLAND *     195388.6211 26793.8597     7.29   0.0000 142868.3478 247908.8943\n",
       "ocean_proximity=NEAR BAY *    8904.6851  2164.9553     4.11   0.0000 4661.0247 13148.3455\n",
       "ocean_proximity=NEAR OCEAN * 23336.6040  1855.7016    12.58   0.0000 19699.1305 26974.0775\n",
       "==============================================================================\n",
       "* p<0.0001, . p<0.05"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5f3f4f",
   "metadata": {},
   "source": [
    "### Pearson-korrelation i den förbättrade modellen\n",
    "\n",
    "För att verifiera att de nya variablerna verkligen minskat multikollineariteten beräknas Pearson-korrelationsmatrisen på nytt. Målet är att inga par av prediktorer ska ha |r| > 0.8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d54dfb55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T16:45:13.278995Z",
     "iopub.status.busy": "2026-02-13T16:45:13.278937Z",
     "iopub.status.idle": "2026-02-13T16:45:13.286795Z",
     "shell.execute_reply": "2026-02-13T16:45:13.286584Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'korrelationsmatris': [[1.0, -0.05, -0.03, 0.06, -0.0, -0.08, 0.0, 0.1, 0.15],\n",
       "  [-0.05, 1.0, -0.19, -0.17, 0.02, -0.19, 0.03, 0.19, 0.05],\n",
       "  [-0.03, -0.19, 1.0, 0.24, 0.03, -0.32, -0.01, 0.1, 0.03],\n",
       "  [0.06, -0.17, 0.24, 1.0, -0.01, 0.14, -0.0, -0.03, -0.05],\n",
       "  [-0.0, 0.02, 0.03, -0.01, 1.0, 0.01, -0.0, -0.01, -0.0],\n",
       "  [-0.08, -0.19, -0.32, 0.14, 0.01, 1.0, -0.02, -0.26, -0.32],\n",
       "  [0.0, 0.03, -0.01, -0.0, -0.0, -0.02, 1.0, -0.01, -0.01],\n",
       "  [0.1, 0.19, 0.1, -0.03, -0.01, -0.26, -0.01, 1.0, -0.11],\n",
       "  [0.15, 0.05, 0.03, -0.05, -0.0, -0.32, -0.01, -0.11, 1.0]],\n",
       " 'legend': {0: 'distance_to_centroid',\n",
       "  1: 'housing_median_age',\n",
       "  2: 'median_income',\n",
       "  3: 'rooms_per_household',\n",
       "  4: 'people_per_household',\n",
       "  5: 'ocean_proximity=INLAND',\n",
       "  6: 'ocean_proximity=ISLAND',\n",
       "  7: 'ocean_proximity=NEAR BAY',\n",
       "  8: 'ocean_proximity=NEAR OCEAN'},\n",
       " 'starka_korrelationer (|r| > 0.8)': 'Inga — multikollineariteten är löst'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearson_2 = model_2.pearson_pairs(X2, include_intercept=False)\n",
    "r_matrix_2 = pearson_2['r']\n",
    "\n",
    "n_feats_2 = len(feature_names_2)\n",
    "starka_korr_2 = {}\n",
    "for i in range(n_feats_2):\n",
    "    for j in range(i + 1, n_feats_2):\n",
    "        if abs(r_matrix_2[i, j]) > 0.8:\n",
    "            starka_korr_2[f'{feature_names_2[i]} <-> {feature_names_2[j]}'] = float(np.round(r_matrix_2[i, j], 3))\n",
    "\n",
    "{\n",
    "    'korrelationsmatris': np.round(r_matrix_2, 2).tolist(),\n",
    "    'legend': {i: name for i, name in enumerate(feature_names_2)},\n",
    "    'starka_korrelationer (|r| > 0.8)': starka_korr_2 if starka_korr_2 else 'Inga — multikollineariteten är löst',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cd9a87",
   "metadata": {},
   "source": [
    "### Konfidensintervall med anpassad konfidensnivå\n",
    "\n",
    "I denna rapport används 95% som huvudnivå för inferens, eftersom det är den etablerade standarden i regressionsanalys och därför mest lämplig för formella slutsatser om parametrarna. Som robusthetskontroll visas även 99% konfidensintervall; att slutsatserna i stort sett är oförändrade visar att resultaten inte är känsliga för ett striktare signifikanskrav. Den 60-procentiga nivån används endast som ett kompletterande, explorativt perspektiv i den förbättrade modellen för att illustrera intervallbredd och praktisk osäkerhet vid modellens aktuella förklaringsgrad (R² ≈ 0.64). Den ersätter alltså inte 95%-analysen, utan fungerar som en pedagogisk jämförelse.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8fea3519",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T16:45:13.287860Z",
     "iopub.status.busy": "2026-02-13T16:45:13.287792Z",
     "iopub.status.idle": "2026-02-13T16:45:13.290859Z",
     "shell.execute_reply": "2026-02-13T16:45:13.290685Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'konfidensniva': 0.6,\n",
       " 'konfidensintervall': {'intercept': {'koefficient': 55452.95,\n",
       "   'CI_low': 52830.76,\n",
       "   'CI_high': 58075.14},\n",
       "  'distance_to_centroid': {'koefficient': -4700.72,\n",
       "   'CI_low': -5138.22,\n",
       "   'CI_high': -4263.23},\n",
       "  'housing_median_age': {'koefficient': 812.84,\n",
       "   'CI_low': 769.71,\n",
       "   'CI_high': 855.96},\n",
       "  'median_income': {'koefficient': 38651.76,\n",
       "   'CI_low': 38320.78,\n",
       "   'CI_high': 38982.73},\n",
       "  'rooms_per_household': {'koefficient': 572.02,\n",
       "   'CI_low': 391.58,\n",
       "   'CI_high': 752.46},\n",
       "  'people_per_household': {'koefficient': -244.19,\n",
       "   'CI_low': -278.09,\n",
       "   'CI_high': -210.29},\n",
       "  'ocean_proximity=INLAND': {'koefficient': -64198.84,\n",
       "   'CI_low': -65334.62,\n",
       "   'CI_high': -63063.05},\n",
       "  'ocean_proximity=ISLAND': {'koefficient': 195388.62,\n",
       "   'CI_low': 172837.54,\n",
       "   'CI_high': 217939.7},\n",
       "  'ocean_proximity=NEAR BAY': {'koefficient': 8904.69,\n",
       "   'CI_low': 7082.55,\n",
       "   'CI_high': 10726.82},\n",
       "  'ocean_proximity=NEAR OCEAN': {'koefficient': 23336.6,\n",
       "   'CI_low': 21774.75,\n",
       "   'CI_high': 24898.46}},\n",
       " 'R2': 0.6435}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2_60 = LinearRegression(confidence_level=0.60, add_intercept=True, drop_first_category=True)\n",
    "model_2_60.fit(X2, y, feature_names=feature_names_2)\n",
    "\n",
    "ci_60 = model_2_60.confidence_intervals()\n",
    "coef_names_60 = ['intercept'] + feature_names_2\n",
    "ci_table = {}\n",
    "for i, name in enumerate(coef_names_60):\n",
    "    ci_table[name] = {\n",
    "        'koefficient': round(float(model_2_60.beta[i]), 2),\n",
    "        'CI_low': round(float(ci_60['lower'][i]), 2),\n",
    "        'CI_high': round(float(ci_60['upper'][i]), 2),\n",
    "    }\n",
    "\n",
    "{\n",
    "    'konfidensniva': 0.60,\n",
    "    'konfidensintervall': ci_table,\n",
    "    'R2': round(model_2_60.r2(), 4),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1831dac7",
   "metadata": {},
   "source": [
    "## 13. Log-linjär modell — att lösa heteroskedasticiteten vid roten\n",
    "\n",
    "De två första modellerna delar ett fundamentalt problem som ingen mängd feature engineering kan lösa: OLS på råa dollarpriser antar att feltermen är *additiv* och har *konstant varians*. Men bostadspriser beter sig inte så. Ett fel på 30 000 dollar betyder en katastrof för en bostad värd 50 000 men är marginellt för en värd 400 000. Prisvariationen är i grunden *multiplikativ* — den skalar med prisnivån. Detta är exakt vad heteroskedasticitetskvoten på ≈ 1.4 och den positiva skevheten avslöjar.\n",
    "\n",
    "Lösningen är att inte modellera $Y$ direkt, utan $\\log(Y)$:\n",
    "\n",
    "$$\\log(Y_i) = X_i\\beta + \\epsilon_i$$\n",
    "\n",
    "Om $\\epsilon_i$ har konstant varians innebär det att felen på den ursprungliga skalan är *procentuella*, inte absoluta — vilket är precis hur bostadsmarknaden fungerar. Förutom att adressera heteroskedasticiteten komprimerar logaritmen den högra svansen i prisfördelningen och gör residualerna mer symmetriska, vilket förbättrar normalitetsantagandet.\n",
    "\n",
    "Utöver log-transformationen görs ytterligare en förbättring: samtliga numeriska särdrag z-standardiseras (subtrahera medelvärdet, dividera med standardavvikelsen) så att koefficienterna uttrycks i samma enhet — antal standardavvikelsers förändring i $\\log(Y)$ — och därmed blir direkt jämförbara i storlek. En koefficient på exempelvis 0.3 betyder att en standardavvikelses ökning i det särdraget är associerad med en 35-procentig ökning i medianpriset ($e^{0.3} \\approx 1.35$).\n",
    "\n",
    "Vid återtransformering till den ursprungliga skalan räcker det inte att bara exponentiera prediktionerna: $E[Y] \\neq \\exp(E[\\log Y])$ på grund av Jensens olikhet. Istället används Duans smearing-estimator, $\\hat{E}[Y_i] = \\exp(\\hat{\\log Y}_i) \\cdot \\frac{1}{n}\\sum_j\\exp(\\hat{e}_j)$, som korrigerar för denna bias. Det är dock viktigt att notera att R² på dollarskalan inte är direkt jämförbart med de linjära modellernas R² — log-modellen optimerar en *annan* förlustfunktion (procentuella fel snarare än absoluta dollarfel). Det relevanta kvalitetsmåttet för log-modellen är dess R² på log-skalan samt residualdiagnostiken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff98191d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T16:45:13.291872Z",
     "iopub.status.busy": "2026-02-13T16:45:13.291817Z",
     "iopub.status.idle": "2026-02-13T16:45:13.298558Z",
     "shell.execute_reply": "2026-02-13T16:45:13.298348Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feature_names': ['z_distance_to_centroid',\n",
       "  'z_housing_median_age',\n",
       "  'z_median_income',\n",
       "  'z_rooms_per_household',\n",
       "  'z_people_per_household',\n",
       "  'ocean_proximity=INLAND',\n",
       "  'ocean_proximity=ISLAND',\n",
       "  'ocean_proximity=NEAR BAY',\n",
       "  'ocean_proximity=NEAR OCEAN'],\n",
       " 'antal_sardrag (d)': 9,\n",
       " 'antal_observationer (n)': 12065,\n",
       " 'respons': 'log(median_house_value)'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_y = np.log(y)\n",
    "\n",
    "num_features_3 = np.column_stack([\n",
    "    distance_to_centroid,\n",
    "    X_num[:, col_idx['housing_median_age']],\n",
    "    X_num[:, col_idx['median_income']],\n",
    "    rooms_per_household,\n",
    "    people_per_household,\n",
    "])\n",
    "num_names_3 = [\n",
    "    'distance_to_centroid',\n",
    "    'housing_median_age',\n",
    "    'median_income',\n",
    "    'rooms_per_household',\n",
    "    'people_per_household',\n",
    "]\n",
    "\n",
    "means_3 = np.mean(num_features_3, axis=0)\n",
    "stds_3 = np.std(num_features_3, axis=0)\n",
    "Z_num_3 = (num_features_3 - means_3) / stds_3\n",
    "\n",
    "X_cat_3, categories_3 = LinearRegression.one_hot_encode(cat, drop_first=True)\n",
    "X3 = np.column_stack([Z_num_3, X_cat_3])\n",
    "feature_names_3 = [f'z_{name}' for name in num_names_3] + [f'{cat_col}={c}' for c in categories_3]\n",
    "\n",
    "model_3 = LinearRegression(confidence_level=0.95, add_intercept=True, drop_first_category=True)\n",
    "model_3.fit(X3, log_y, feature_names=feature_names_3)\n",
    "\n",
    "{\n",
    "    'feature_names': feature_names_3,\n",
    "    'antal_sardrag (d)': model_3.d,\n",
    "    'antal_observationer (n)': model_3.n,\n",
    "    'respons': 'log(median_house_value)',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a36be267",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T16:45:13.299551Z",
     "iopub.status.busy": "2026-02-13T16:45:13.299495Z",
     "iopub.status.idle": "2026-02-13T16:45:13.302492Z",
     "shell.execute_reply": "2026-02-13T16:45:13.302297Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "============================= REGRESSION RESULTS =============================\n",
       "Observations: 12065           R-squared:      0.6626\n",
       "Features:     9               Adj. R-squared: 0.6624\n",
       "RMSE:         0.3226          F-statistic:    2630.8143\n",
       "Res. Std Err: 0.3227          Prob (F-stat):  0\n",
       "------------------------------------------------------------------------------\n",
       "                                   Coef    Std Err        t    P>|t| [95.0% Conf. Int.]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept *                     12.1849     0.0050  2418.54   0.0000  12.1750  12.1948\n",
       "z_distance_to_centroid *        -0.0230     0.0030    -7.58   0.0000  -0.0289  -0.0170\n",
       "z_housing_median_age *           0.0203     0.0032     6.38   0.0000   0.0140   0.0265\n",
       "z_median_income *                0.3176     0.0034    93.57   0.0000   0.3109   0.3243\n",
       "z_rooms_per_household .          0.0115     0.0031     3.68   0.0002   0.0054   0.0177\n",
       "z_people_per_household *        -0.0156     0.0029    -5.30   0.0000  -0.0214  -0.0098\n",
       "ocean_proximity=INLAND *        -0.4541     0.0073   -62.41   0.0000  -0.4684  -0.4399\n",
       "ocean_proximity=ISLAND *         0.8269     0.1445     5.72   0.0000   0.5437   1.1101\n",
       "ocean_proximity=NEAR BAY .       0.0249     0.0117     2.13   0.0331   0.0020   0.0478\n",
       "ocean_proximity=NEAR OCEAN *     0.0764     0.0100     7.64   0.0000   0.0568   0.0960\n",
       "==============================================================================\n",
       "* p<0.0001, . p<0.05"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af021af4",
   "metadata": {},
   "source": [
    "### Pearson-korrelation och residualdiagnostik för log-modellen\n",
    "\n",
    "Först verifieras att multikollineariteten förblir låg efter standardiseringen. Därefter genomförs samma residualdiagnostik som för den första modellen, nu på log-skalan. Om log-transformationen har fungerat bör vi se: (1) en heteroskedasticitetskvot nära 1.0 istället för 1.4, (2) markant lägre skevhet, och (3) lägre excess kurtosis. Slutligen återtransformeras prediktionerna till dollar med hjälp av Duans smearing-estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff5dca7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T16:45:13.303554Z",
     "iopub.status.busy": "2026-02-13T16:45:13.303494Z",
     "iopub.status.idle": "2026-02-13T16:45:13.314664Z",
     "shell.execute_reply": "2026-02-13T16:45:13.314441Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'starka_korrelationer (|r| > 0.8)': 'Inga',\n",
       " 'residualdiagnostik_jamforelse': {'Modell 1 (linjar)': {'skevhet': 0.9684,\n",
       "   'heteroskedasticitet_kvot': 1.346},\n",
       "  'Modell 3 (log-linjar)': {'skevhet': 0.1112,\n",
       "   'heteroskedasticitet_kvot': 0.82},\n",
       "  'forbattring_skevhet': '0.97 -> 0.11 (89% reduktion)',\n",
       "  'forbattring_heteroskedasticitet': '1.346 -> 0.820 (nara 1.0 = perfekt)'},\n",
       " 'residualdetaljer_log_skala': {'medelvarde': 0.0,\n",
       "  'std': 0.3226,\n",
       "  'min': -2.6915,\n",
       "  'Q1': -0.2087,\n",
       "  'median': -0.0138,\n",
       "  'Q3': 0.1935,\n",
       "  'max': 1.654,\n",
       "  'kurtosis': 1.6466},\n",
       " 'normalitetstest (DAgostino-Pearson)': {'p_varde': 2.6033680585979694e-103,\n",
       "  'notering': 'Formellt forkastad men drastiskt forbattrad fordelningsform'}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearson_3 = model_3.pearson_pairs(X3, include_intercept=False)\n",
    "r_matrix_3 = pearson_3['r']\n",
    "\n",
    "n_feats_3 = len(feature_names_3)\n",
    "starka_korr_3 = {}\n",
    "for i in range(n_feats_3):\n",
    "    for j in range(i + 1, n_feats_3):\n",
    "        if abs(r_matrix_3[i, j]) > 0.8:\n",
    "            starka_korr_3[f'{feature_names_3[i]} <-> {feature_names_3[j]}'] = round(r_matrix_3[i, j], 3)\n",
    "\n",
    "log_residuals = model_3.residuals()\n",
    "log_pred = model_3.predict(X3)\n",
    "\n",
    "log_quartiles = np.percentile(log_residuals, [0, 25, 50, 75, 100])\n",
    "_, log_normaltest_p = normaltest(log_residuals)\n",
    "\n",
    "log_low = log_pred < np.median(log_pred)\n",
    "log_high = ~log_low\n",
    "log_std_low = float(np.std(log_residuals[log_low]))\n",
    "log_std_high = float(np.std(log_residuals[log_high]))\n",
    "\n",
    "log_skew = float(np.mean((log_residuals - np.mean(log_residuals))**3) / np.std(log_residuals)**3)\n",
    "log_kurt = float(np.mean((log_residuals - np.mean(log_residuals))**4) / np.std(log_residuals)**4 - 3)\n",
    "\n",
    "residuals_m1 = model.residuals()\n",
    "y_pred_m1 = model.predict(X)\n",
    "low_m1 = y_pred_m1 < np.median(y_pred_m1)\n",
    "skew_m1 = float(np.mean((residuals_m1 - np.mean(residuals_m1))**3) / np.std(residuals_m1)**3)\n",
    "het_m1 = float(np.std(residuals_m1[~low_m1]) / np.std(residuals_m1[low_m1]))\n",
    "\n",
    "{\n",
    "    'starka_korrelationer (|r| > 0.8)': starka_korr_3 if starka_korr_3 else 'Inga',\n",
    "    'residualdiagnostik_jamforelse': {\n",
    "        'Modell 1 (linjar)': {\n",
    "            'skevhet': round(skew_m1, 4),\n",
    "            'heteroskedasticitet_kvot': round(het_m1, 3),\n",
    "        },\n",
    "        'Modell 3 (log-linjar)': {\n",
    "            'skevhet': round(log_skew, 4),\n",
    "            'heteroskedasticitet_kvot': round(log_std_high / log_std_low, 3),\n",
    "        },\n",
    "        'forbattring_skevhet': f'{abs(skew_m1):.2f} -> {abs(log_skew):.2f} ({(1 - abs(log_skew)/abs(skew_m1))*100:.0f}% reduktion)',\n",
    "        'forbattring_heteroskedasticitet': f'{het_m1:.3f} -> {log_std_high/log_std_low:.3f} (nara 1.0 = perfekt)',\n",
    "    },\n",
    "    'residualdetaljer_log_skala': {\n",
    "        'medelvarde': round(float(np.mean(log_residuals)), 6),\n",
    "        'std': round(float(np.std(log_residuals)), 4),\n",
    "        'min': round(float(log_quartiles[0]), 4),\n",
    "        'Q1': round(float(log_quartiles[1]), 4),\n",
    "        'median': round(float(log_quartiles[2]), 4),\n",
    "        'Q3': round(float(log_quartiles[3]), 4),\n",
    "        'max': round(float(log_quartiles[4]), 4),\n",
    "        'kurtosis': round(log_kurt, 4),\n",
    "    },\n",
    "    'normalitetstest (DAgostino-Pearson)': {\n",
    "        'p_varde': float(log_normaltest_p),\n",
    "        'notering': 'Formellt forkastad men drastiskt forbattrad fordelningsform',\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "65304303",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T16:45:13.315646Z",
     "iopub.status.busy": "2026-02-13T16:45:13.315593Z",
     "iopub.status.idle": "2026-02-13T16:45:13.319871Z",
     "shell.execute_reply": "2026-02-13T16:45:13.319645Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'duan_smearing_factor': 1.0547,\n",
       " 'jamforelse': {'Modell 1 (alla variabler, linjar)': {'R2': 0.6858,\n",
       "   'RMSE_dollar': 56161.0,\n",
       "   'sardrag': 12,\n",
       "   'multikollinearitet': '7 par med |r|>0.8',\n",
       "   'skevhet': 0.97,\n",
       "   'hetero_kvot': 1.346,\n",
       "   'median_procentfel': 19.0},\n",
       "  'Modell 2 (kvotvariabler, linjar)': {'R2': 0.6435,\n",
       "   'RMSE_dollar': 59818.0,\n",
       "   'sardrag': 9,\n",
       "   'multikollinearitet': '0 par'},\n",
       "  'Modell 3 (log-linjar, z-standardiserad)': {'R2_log_skala': 0.6626,\n",
       "   'R2_dollar_Duan': 0.494,\n",
       "   'RMSE_dollar': 71268.0,\n",
       "   'sardrag': 9,\n",
       "   'multikollinearitet': '0 par',\n",
       "   'skevhet': 0.11,\n",
       "   'hetero_kvot': 0.82,\n",
       "   'median_procentfel': 21.3}},\n",
       " 'notering': 'R2 pa dollar-skalan ar INTE rattvisande for log-modellen — den optimerar procentuella fel, inte absoluta. Median procentfel ar det mer relevanta mattet.'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smearing_factor = float(np.mean(np.exp(log_residuals)))\n",
    "y_pred_log_bt = np.exp(log_pred) * smearing_factor\n",
    "\n",
    "ss_res_bt = float(np.sum((y - y_pred_log_bt)**2))\n",
    "ss_tot = float(np.sum((y - np.mean(y))**2))\n",
    "r2_bt = 1.0 - ss_res_bt / ss_tot\n",
    "rmse_bt = float(np.sqrt(np.mean((y - y_pred_log_bt)**2)))\n",
    "\n",
    "rmse_m1 = float(np.sqrt(np.mean((y - y_pred_m1)**2)))\n",
    "y_pred_m2 = model_2.predict(X2)\n",
    "rmse_m2 = float(np.sqrt(np.mean((y - y_pred_m2)**2)))\n",
    "\n",
    "pct_errors = (y - y_pred_log_bt) / y * 100\n",
    "pct_errors_m1 = (y - y_pred_m1) / y * 100\n",
    "\n",
    "{\n",
    "    'duan_smearing_factor': round(smearing_factor, 4),\n",
    "    'jamforelse': {\n",
    "        'Modell 1 (alla variabler, linjar)': {\n",
    "            'R2': round(model.r2(), 4),\n",
    "            'RMSE_dollar': round(rmse_m1, 0),\n",
    "            'sardrag': model.d,\n",
    "            'multikollinearitet': '7 par med |r|>0.8',\n",
    "            'skevhet': round(skew_m1, 2),\n",
    "            'hetero_kvot': round(het_m1, 3),\n",
    "            'median_procentfel': round(float(np.median(np.abs(pct_errors_m1))), 1),\n",
    "        },\n",
    "        'Modell 2 (kvotvariabler, linjar)': {\n",
    "            'R2': round(model_2.r2(), 4),\n",
    "            'RMSE_dollar': round(rmse_m2, 0),\n",
    "            'sardrag': model_2.d,\n",
    "            'multikollinearitet': '0 par',\n",
    "        },\n",
    "        'Modell 3 (log-linjar, z-standardiserad)': {\n",
    "            'R2_log_skala': round(model_3.r2(), 4),\n",
    "            'R2_dollar_Duan': round(r2_bt, 4),\n",
    "            'RMSE_dollar': round(rmse_bt, 0),\n",
    "            'sardrag': model_3.d,\n",
    "            'multikollinearitet': '0 par',\n",
    "            'skevhet': round(log_skew, 2),\n",
    "            'hetero_kvot': round(log_std_high / log_std_low, 3),\n",
    "            'median_procentfel': round(float(np.median(np.abs(pct_errors))), 1),\n",
    "        },\n",
    "    },\n",
    "    'notering': 'R2 pa dollar-skalan ar INTE rattvisande for log-modellen — den optimerar procentuella fel, inte absoluta. Median procentfel ar det mer relevanta mattet.',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464afd77",
   "metadata": {},
   "source": [
    "## 14. Sammanfattning och diskussion\n",
    "\n",
    "Analysen genomfördes i tre steg där varje modell byggde vidare på föregående resultat.\n",
    "\n",
    "**Modell 1** inkluderade samtliga originalvariabler och visade hög förklaringsgrad (R² ≈ 0.69), men också tydlig multikollinearitet (sju par med |r| > 0.8) samt heteroskedastiska och positivt sneda residualer (skevhet ≈ 0.97, heteroskedasticitetskvot ≈ 1.35). Det gör enskilda koefficienttolkningar mindre stabila.\n",
    "\n",
    "**Modell 2** ersatte blockstorlek-variabler med kvoter (`rooms_per_household`, `people_per_household`) och ersatte koordinater med `distance_to_centroid`. Detta eliminerade starka linjära beroenden (0 par med |r| > 0.8) och gav mer tolkbara koefficienter, men residualproblemen kvarstod i huvudsak.\n",
    "\n",
    "**Modell 3** log-transformerade responsen och z-standardiserade numeriska särdrag. Det gav tydligt bättre antagandeuppfyllelse: skevheten minskade från ca 0.97 till 0.11 (cirka 89% reduktion) och heteroskedasticitetskvoten gick från ca 1.35 till 0.82 (närmare 1.0). Därmed blir inferens (standardfel, p-värden och konfidensintervall) mer robust. R² på log-skalan (≈ 0.66) är inte direkt jämförbart med linjära modellers R² på dollarskalan eftersom förlustfunktionerna skiljer sig.\n",
    "\n",
    "Den statistiska tolkningen måste gå bortom ett binärt fokus på p-värden. I stora datamängder innebär ett litet standardfel att även obetydliga effekter blir signifikanta. Koeficienterna beskriver modellens förväntade förändring i bostadspris givet en marginal förändring i prediktorn, men tolkningen är meningsfull endast om intervallet är tillräckligt smalt och effekten är praktiskt relevant. Konfidensintervallens bredd ska därför jämföras med koefficienternas storlek och med vad som är rimligt på bostadsmarknaden.\n",
    "\n",
    "Det är dessutom viktigt att skilja mellan korrelation och kausalitet. OLS-modellen identifierar statistiska samband mellan särdrag och bostadspris, men den bevisar inte att ett högre `median_income` *orsakar* ett högre pris. Både inkomster och bostadspriser kan styras av gemensamma socioekonomiska eller geografiska faktorer. För att etablera kausala samband skulle man behöva kontrollerade experiment eller specifika kausala modeller. Resultaten i denna rapport ska därför läsas som prediktiva och associativa.\n",
    "\n",
    "Multikollinearitetens effektkedja kan sammanfattas som: stark korrelation mellan prediktorer → högre koefficientvarians → större standardfel → bredare konfidensintervall → lägre styrka i t-tester → svagare tolkbarhet av enskilda koefficienter. Det påverkar främst inferensens tillförlitlighet snarare än modellens prediktiva kraft, vilket förklarar varför R² kan vara högt samtidigt som koefficienterna är instabila.\n",
    "\n",
    "Sammanfattningsvis är Modell 1 stark för prediktion i absoluta dollar, Modell 2 reducerar multikollineariteten och ger tydligare särdragsbidrag, medan Modell 3 ger den mest statistiskt tillförlitliga tolkningen genom bättre uppfyllelse av modellantagandena.”}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
