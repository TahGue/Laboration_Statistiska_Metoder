{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0d28504",
   "metadata": {},
   "source": [
    "# Linj√§r Regressionsanalys av Bostadspriser i Kalifornien\n",
    "\n",
    "## Introduktion\n",
    "\n",
    "I denna laboration unders√∂ks sambandet mellan ett antal variabler som beskriver bostadsomr√•den i Kalifornien och det medianbostadsv√§rde som observerats i respektive omr√•de. Datasetet, som h√§rr√∂r fr√•n folkr√§kningen 1990, inneh√•ller 20 640 observationer och beskriver varje censusblock med uppgifter om bland annat medianinkomst, hus√•lder, antal rum, befolkningsstorlek, geografisk position och n√§rheten till havet.\n",
    "\n",
    "Responsvariabeln i analysen √§r `median_house_value`, det vill s√§ga medianpriset p√• bost√§der i ett givet block. Syftet √§r att med hj√§lp av multipel linj√§r regression (OLS) skatta hur de tillg√§ngliga variablerna bidrar till att f√∂rklara prisvariationen, och att unders√∂ka modellens styrkor och svagheter med statistiska verktyg: signifikanstest, konfidensintervall, Pearson-korrelation och residualdiagnostik."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9f60ed",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0607e146",
   "metadata": {},
   "source": [
    "## Metod\n",
    "\n",
    "Modellen implementeras i en egen klass (`LinearRegression` i `linear_regression.py`) som enbart anv√§nder numpy f√∂r linj√§r algebra och scipy.stats f√∂r f√∂rdelningar och test. Inga f√§rdiga regressionsimplementationer eller visualiseringsbibliotek anv√§nds.\n",
    "\n",
    "Arbetsg√•ngen b√∂rjar med att l√§sa in CSV-filen och konvertera alla v√§rden till numeriska arrayer. Kolumnen `total_bedrooms` inneh√•ller 207 saknade v√§rden, vilka imputeras med kolumnens medelv√§rde f√∂r att bevara stickprovsstorleken. Eftersom datasetet inneh√•ller flera censusblock med identiska koordinater aggregeras sedan observationerna per unik (longitude, latitude)-kombination: additiva variabler (`total_rooms`, `total_bedrooms`, `population`, `households`) summeras, medan niv√•variabler (`housing_median_age`, `median_income`, `median_house_value`) ers√§tts av medelv√§rdet inom gruppen. Dessutom tas alla observationer med `median_house_value` = 500 001 bort, eftersom detta v√§rde utg√∂r en artificiell cap som bryter mot OLS-antagandena.\n",
    "\n",
    "Den kategoriska variabeln `ocean_proximity` one-hot-kodas med referenskategorin `<1H OCEAN` utel√§mnad (drop-first) f√∂r att undvika linj√§rt beroende med interceptet.\n",
    "\n",
    "Analysen genomf√∂rs i tre steg. F√∂rst skattas en fullst√§ndig modell med samtliga originalvariabler f√∂r att identifiera multikollinearitet och andra problem. D√§refter konstrueras en f√∂rb√§ttrad modell d√§r de starkt korrelerade blockstorlek-variablerna ers√§tts med kvotvariabler (`rooms_per_household`, `people_per_household`) och koordinaterna ers√§tts av ett enda avst√•ndsm√•tt (`distance_to_centroid`). Slutligen angrips det kvarvarande problemet ‚Äî heteroskedasticitet och icke-normalf√∂rdelade residualer ‚Äî genom en log-linj√§r modell: responsvariabeln log-transformeras och de numeriska s√§rdragen z-standardiseras. Log-transformationen bygger p√• insikten att bostadspriser i grunden √§r multiplikativa ‚Äî en procentuell felterm √§r mer realistisk √§n en absolut ‚Äî och den g√∂r OLS-antagandena mer rimliga.\n",
    "\n",
    "Koefficienterna skattas med normalequationen $\\hat{\\beta} = (X^TX)^{-1}X^Ty$. Implementationen anv√§nder `np.linalg.pinv` i st√§llet f√∂r en vanlig invers, vilket inneb√§r att ber√§kningen inte kraschar om $X^TX$ √§r singul√§r eller n√§ra-singul√§r. Det √§r dock viktigt att f√∂rst√• att pseudoinversen inte l√∂ser de statistiska problem som multikollinearitet medf√∂r ‚Äî den ger enbart en numerisk l√∂sning.\n",
    "\n",
    "Efter skattningen utv√§rderas varje modell genom F-test och R¬≤ f√∂r √∂vergripande signifikans, t-test och konfidensintervall f√∂r enskilda koefficienter, Pearson-korrelation f√∂r att identifiera multikollinearitet, samt residualstatistik f√∂r att bed√∂ma modellens antaganden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ce57163",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "from scipy.stats import normaltest\n",
    "from linear_regression import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2b4109",
   "metadata": {},
   "source": [
    "## 1. Datainl√§sning och f√∂rbehandling\n",
    "\n",
    "Datasetet l√§ses in fr√•n `housing.csv` med Pythons csv-modul. Varje rad representerar ett censusblock. De √•tta numeriska kolumnerna konverteras till flyttal, och tomma celler tolkas som saknade v√§rden (NaN). Dessa ers√§tts med respektive kolumns medelv√§rde.\n",
    "\n",
    "Eftersom datasetet inneh√•ller flera block med identiska koordinater (samma longitud och latitud) aggregeras sedan observationerna per unik geografisk punkt: additiva variabler summeras och niv√•variabler medelv√§rderas. D√§refter tas alla observationer bort d√§r `median_house_value` √§r exakt 500 001, eftersom detta v√§rde representerar en artificiell √∂vre gr√§ns i datasetet. Att beh√•lla dessa censurerade observationer skulle systematiskt snedvrida modellens residualer i det √∂vre prisintervallet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9f8ce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'observationer': 20640,\n",
       " 'numeriska_sardrag': 8,\n",
       " 'kategorisk_variabel': 'ocean_proximity',\n",
       " 'responsvariabel': 'median_house_value',\n",
       " 'saknade_varden_fore_imputering': {'total_bedrooms': 207},\n",
       " 'imputering': 'kolumnmedelvarde'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'housing.csv'\n",
    "with open(path, newline='', encoding='utf-8') as f:\n",
    "    r = csv.DictReader(f)\n",
    "    rows = list(r)\n",
    "cols_num = [\n",
    "    'longitude','latitude','housing_median_age','total_rooms','total_bedrooms',\n",
    "    'population','households','median_income'\n",
    "]\n",
    "y_col = 'median_house_value'\n",
    "cat_col = 'ocean_proximity'\n",
    "\n",
    "n_raw = len(rows)\n",
    "X_raw = np.empty((n_raw, len(cols_num)), dtype=float)\n",
    "y_raw = np.empty(n_raw, dtype=float)\n",
    "cat_raw = np.empty(n_raw, dtype=object)\n",
    "for i, row in enumerate(rows):\n",
    "    for j, c in enumerate(cols_num):\n",
    "        v = row[c]\n",
    "        X_raw[i, j] = float(v) if v != '' else np.nan\n",
    "    y_raw[i] = float(row[y_col])\n",
    "    cat_raw[i] = row[cat_col]\n",
    "\n",
    "missing_before = {c: int(np.isnan(X_raw[:, j]).sum()) for j, c in enumerate(cols_num)}\n",
    "\n",
    "col_means = np.nanmean(X_raw, axis=0)\n",
    "nan_inds = np.where(np.isnan(X_raw))\n",
    "X_raw[nan_inds] = np.take(col_means, nan_inds[1])\n",
    "\n",
    "sum_cols = {'total_rooms', 'total_bedrooms', 'population', 'households'}\n",
    "mean_cols = {'housing_median_age', 'median_income'}\n",
    "col_idx = {c: j for j, c in enumerate(cols_num)}\n",
    "\n",
    "groups = {}\n",
    "for i in range(n_raw):\n",
    "    key = (X_raw[i, col_idx['longitude']], X_raw[i, col_idx['latitude']])\n",
    "    if key not in groups:\n",
    "        groups[key] = []\n",
    "    groups[key].append(i)\n",
    "\n",
    "n_unique = len(groups)\n",
    "X_agg = np.empty((n_unique, len(cols_num)), dtype=float)\n",
    "y_agg = np.empty(n_unique, dtype=float)\n",
    "cat_agg = np.empty(n_unique, dtype=object)\n",
    "\n",
    "for g_idx, (key, indices) in enumerate(groups.items()):\n",
    "    idx_arr = np.array(indices)\n",
    "    for j, c in enumerate(cols_num):\n",
    "        if c in sum_cols:\n",
    "            X_agg[g_idx, j] = np.sum(X_raw[idx_arr, j])\n",
    "        elif c in mean_cols:\n",
    "            X_agg[g_idx, j] = np.mean(X_raw[idx_arr, j])\n",
    "        else:\n",
    "            X_agg[g_idx, j] = X_raw[idx_arr[0], j]\n",
    "    y_agg[g_idx] = np.mean(y_raw[idx_arr])\n",
    "    cat_agg[g_idx] = cat_raw[indices[0]]\n",
    "\n",
    "cap_mask = y_agg < 500001\n",
    "X_num = X_agg[cap_mask]\n",
    "y = y_agg[cap_mask]\n",
    "cat = cat_agg[cap_mask]\n",
    "n = len(y)\n",
    "\n",
    "{\n",
    "    'observationer_ratt': n_raw,\n",
    "    'saknade_varden_fore_imputering': {k: v for k, v in missing_before.items() if v > 0},\n",
    "    'unika_koordinater': n_unique,\n",
    "    'borttagna_cappade (y=500001)': int((~cap_mask).sum()),\n",
    "    'observationer_efter_rensning': n,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e451b60",
   "metadata": {},
   "source": [
    "## 2. Explorativ dataanalys (EDA)\n",
    "\n",
    "F√∂r att f√• en √∂verblick av datasetet ber√§knas deskriptiv statistik (minimum, medelv√§rde, median, maximum och standardavvikelse) f√∂r samtliga numeriska variabler samt responsvariabeln. Dessutom unders√∂ks f√∂rdelningen av den kategoriska variabeln `ocean_proximity`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33933b82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'deskriptiv_statistik': {'longitude': {'min': -124.35,\n",
       "   'medel': -119.57,\n",
       "   'median': -118.49,\n",
       "   'max': -114.31,\n",
       "   'std': 2.0},\n",
       "  'latitude': {'min': 32.54,\n",
       "   'medel': 35.63,\n",
       "   'median': 34.26,\n",
       "   'max': 41.95,\n",
       "   'std': 2.14},\n",
       "  'housing_median_age': {'min': 1.0,\n",
       "   'medel': 28.64,\n",
       "   'median': 29.0,\n",
       "   'max': 52.0,\n",
       "   'std': 12.59},\n",
       "  'total_rooms': {'min': 2.0,\n",
       "   'medel': 2635.76,\n",
       "   'median': 2127.0,\n",
       "   'max': 39320.0,\n",
       "   'std': 2181.56},\n",
       "  'total_bedrooms': {'min': 1.0,\n",
       "   'medel': 537.87,\n",
       "   'median': 438.0,\n",
       "   'max': 6445.0,\n",
       "   'std': 419.26},\n",
       "  'population': {'min': 3.0,\n",
       "   'medel': 1425.48,\n",
       "   'median': 1166.0,\n",
       "   'max': 35682.0,\n",
       "   'std': 1132.43},\n",
       "  'households': {'min': 1.0,\n",
       "   'medel': 499.54,\n",
       "   'median': 409.0,\n",
       "   'max': 6082.0,\n",
       "   'std': 382.32},\n",
       "  'median_income': {'min': 0.5,\n",
       "   'medel': 3.87,\n",
       "   'median': 3.53,\n",
       "   'max': 15.0,\n",
       "   'std': 1.9},\n",
       "  'median_house_value': {'min': 14999.0,\n",
       "   'medel': 206855.82,\n",
       "   'median': 179700.0,\n",
       "   'max': 500001.0,\n",
       "   'std': 115392.82}},\n",
       " 'ocean_proximity_fordelning': {np.str_('<1H OCEAN'): 9136,\n",
       "  np.str_('INLAND'): 6551,\n",
       "  np.str_('ISLAND'): 5,\n",
       "  np.str_('NEAR BAY'): 2290,\n",
       "  np.str_('NEAR OCEAN'): 2658}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_cols = cols_num + [y_col]\n",
    "all_data = np.column_stack([X_num, y])\n",
    "\n",
    "descriptive = {}\n",
    "for j, name in enumerate(all_cols):\n",
    "    col = all_data[:, j]\n",
    "    descriptive[name] = {\n",
    "        'min': round(float(np.min(col)), 2),\n",
    "        'medel': round(float(np.mean(col)), 2),\n",
    "        'median': round(float(np.median(col)), 2),\n",
    "        'max': round(float(np.max(col)), 2),\n",
    "        'std': round(float(np.std(col)), 2),\n",
    "    }\n",
    "\n",
    "ocean_categories, ocean_counts = np.unique(cat.astype(str), return_counts=True)\n",
    "kategori_fordelning = {c: int(cnt) for c, cnt in zip(ocean_categories, ocean_counts)}\n",
    "\n",
    "{\n",
    "    'deskriptiv_statistik': descriptive,\n",
    "    'ocean_proximity_fordelning': kategori_fordelning,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b916b4f",
   "metadata": {},
   "source": [
    "### Diskussion kring s√§rdragsval\n",
    "\n",
    "Analysen genomf√∂rs i tv√• steg. I det f√∂rsta steget inkluderas samtliga tillg√§ngliga numeriska variabler samt den kategoriska variabeln `ocean_proximity`. Detta g√∂rs medvetet f√∂r att kunna identifiera och studera multikollinearitet ‚Äî fyra av variablerna (`total_rooms`, `total_bedrooms`, `population`, `households`) m√§ter alla blockstorlek och √§r d√§rmed starkt korrelerade (Pearson-r mellan 0.86 och 0.97). Att inkludera samtliga g√∂r det m√∂jligt att visa hur korrelationsanalysen avsl√∂jar dessa problem och vilka konsekvenser det f√•r f√∂r signifikanstesterna.\n",
    "\n",
    "I det andra steget konstrueras en f√∂rb√§ttrad modell som adresserar de identifierade problemen. De fyra blockstorlek-variablerna ers√§tts med tv√• kvotvariabler: `rooms_per_household` och `people_per_household`. Koordinaterna `longitude` och `latitude`, som ocks√• uppvisar stark korrelation (r ‚âà ‚àí0.92), ers√§tts av ett enda avst√•ndsm√•tt ‚Äî det euklidiska avst√•ndet till datasetets geografiska centroid. Dessa transformationer minskar kollineariteten avsev√§rt och g√∂r de kvarvarande koefficienterna stabilare och mer tolkbara.\n",
    "\n",
    "Variabeln `ocean_proximity` one-hot-kodas med referenskategorin `<1H OCEAN` utel√§mnad (drop-first), vilket √§r n√∂dv√§ndigt f√∂r att undvika att dummy-variablerna bildar en linj√§rkombination med interceptet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7d34ed",
   "metadata": {},
   "source": [
    "## 3. Modellskattning\n",
    "\n",
    "Designmatrisen konstrueras genom att sammanfoga de √•tta numeriska kolumnerna med de fyra dummy-variablerna fr√•n one-hot-kodningen (fem kategorier minus en referenskategori). Klassen l√§gger automatiskt till en kolumn med ettor f√∂r interceptet, vilket ger totalt 13 kolumner i designmatrisen och 12 skattade s√§rdragskoefficienter ut√∂ver interceptet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3637690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feature_names': ['longitude',\n",
       "  'latitude',\n",
       "  'housing_median_age',\n",
       "  'total_rooms',\n",
       "  'total_bedrooms',\n",
       "  'population',\n",
       "  'households',\n",
       "  'median_income',\n",
       "  'ocean_proximity=INLAND',\n",
       "  'ocean_proximity=ISLAND',\n",
       "  'ocean_proximity=NEAR BAY',\n",
       "  'ocean_proximity=NEAR OCEAN'],\n",
       " 'antal_sardrag (d)': 12,\n",
       " 'antal_observationer (n)': 20640}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearRegression(confidence_level=0.95, add_intercept=True, drop_first_category=True)\n",
    "X_cat, categories = model.one_hot_encode(cat, drop_first=model.drop_first_category)\n",
    "X = np.column_stack([X_num, X_cat])\n",
    "feature_names = cols_num + [f'{cat_col}={c}' for c in categories]\n",
    "model.fit(X, y, feature_names=feature_names)\n",
    "\n",
    "{\n",
    "    'feature_names': feature_names,\n",
    "    'antal_sardrag (d)': model.d,\n",
    "    'antal_observationer (n)': model.n,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0263d73a",
   "metadata": {},
   "source": [
    "## 4. Felmetrik\n",
    "\n",
    "De grundl√§ggande felm√•tten ger en uppfattning om hur stora avvikelser modellen producerar. Variansen $s^2$ √§r en v√§ntev√§rdesriktig skattning av feltermens varians (med $n - d - 1$ i n√§mnaren), standardavvikelsen $s$ √§r dess kvadratrot, och RMSE ber√§knas som kvadratroten ur det genomsnittliga kvadratfelet. RMSE och $s$ ligger n√§ra varandra h√§r eftersom $n$ √§r stort relativt $d$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "70e09f24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'varians (s¬≤)': 4723656867.172138,\n",
       " 'standardavvikelse (s)': 68728.86487620858,\n",
       " 'RMSE': 68707.21720238509}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "    'varians (s¬≤)': model.variance(),\n",
    "    'standardavvikelse (s)': model.standard_deviation(),\n",
    "    'RMSE': model.rmse(),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356adccd",
   "metadata": {},
   "source": [
    "## 5. √ñvergripande modellrelevans och signifikans\n",
    "\n",
    "F-testet pr√∂var nollhypotesen att samtliga koefficienter (utom interceptet) √§r noll, det vill s√§ga att ingen av de inkluderade variablerna bidrar till att f√∂rklara responsvariabeln. R¬≤ anger andelen av den totala variansen i Y som f√∂rklaras av regressionen. Justerat R¬≤ korrigerar f√∂r antalet parametrar och ger en mer r√§ttvisande bild vid m√•nga s√§rdrag, men i detta fall med $n \\approx 12\\,000$ och $d = 12$ √§r skillnaden f√∂rsumbar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fcbe5336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'R¬≤': 0.6454747751244776,\n",
       " 'justerat_R¬≤': 0.6452685259026564,\n",
       " 'F-test': {'f_stat': 3129.586475162513,\n",
       "  'df1': 12,\n",
       "  'df2': 20627,\n",
       "  'p_value': 0.0}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "    'R¬≤': model.r2(),\n",
    "    'justerat_R¬≤': model.adjusted_r2(),\n",
    "    'F-test': model.f_test(),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2af142",
   "metadata": {},
   "source": [
    "## 6. Individuella koefficienttest och konfidensintervall\n",
    "\n",
    "Tabellen nedan redovisar varje koefficients skattade v√§rde, standardfel, t-statistika, p-v√§rde och 95-procentigt konfidensintervall.\n",
    "\n",
    "Ett 95-procentigt konfidensintervall √§r den konventionella niv√•n, men vid ett stickprov av denna storlek ($n \\approx 12\\,000$) √§r det v√§rt att reflektera √∂ver vad det faktiskt inneb√§r. Med s√• m√•nga observationer ger redan mycket svaga samband statistiskt signifikanta t-v√§rden, eftersom standardfelen krymper proportionellt mot $1/\\sqrt{n}$. En variabel kan allts√• vara \"signifikant\" i statistisk mening utan att ha en praktiskt meningsfull effekt p√• bostadspriset. Exempelvis har `total_rooms` ett p-v√§rde n√§ra noll men en koefficient p√• bara ‚àí1.9, vilket inneb√§r att ett extra rum i blocket knappt p√•verkar medianpriset. En str√§ngare niv√•, till exempel 99%, √§ndrar inte bilden n√§mnv√§rt h√§r ‚Äî n√§stan alla koefficienter f√∂rblir signifikanta ‚Äî men det √§r viktigt att inte f√∂rv√§xla statistisk signifikans med praktisk relevans.\n",
    "\n",
    "Det √§r ocks√• avg√∂rande att beakta multikollineariteten. T-testet f√∂r en enskild koefficient testar om just den variabeln bidrar signifikant givet att alla andra variabler redan finns i modellen. N√§r flera variabler m√§ter ungef√§r samma sak (som `total_rooms`, `total_bedrooms`, `households` och `population`) delar de p√• f√∂rklaringskraften, vilket bl√•ser upp standardfelen och g√∂r de individuella testen op√•litliga. En variabel kan framst√• som icke-signifikant, inte f√∂r att den saknar samband med Y, utan f√∂r att en annan, starkt korrelerad variabel redan f√•ngar samma information. Resultaten f√∂r de fyra blockstorlek-variablerna b√∂r d√§rf√∂r tolkas som grupp snarare √§n var f√∂r sig."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2ba2e088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   / \\__\n",
       "  (    @\\___   Regression Rex says:\n",
       "  /         O  'ü§∑ MEH... (Better than guessing)'\n",
       " /   (_____/\n",
       "/_____/   U\n",
       "\n",
       "================================= STATS DUMP =================================\n",
       "Observations: 20640           R-squared:      0.6455\n",
       "Features:     12              Adj. R-squared: 0.6453\n",
       "RMSE:         68707.2172      F-statistic:    3129.5865\n",
       "Res. Std Err: 68728.8649      Prob (F-stat):  0\n",
       "------------------------------------------------------------------------------\n",
       "                                   Coef    Std Err        t    P>|t| [95.0% Conf. Int.]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept *                  -2235716.9130 87495.1155   -25.55   0.0000 -2407214.2514 -2064219.5745\n",
       "longitude *                  -26458.2894  1014.0350   -26.09   0.0000 -28445.8781 -24470.7007\n",
       "latitude *                   -25197.1990   999.9078   -25.20   0.0000 -27157.0972 -23237.3008\n",
       "housing_median_age *          1057.8638    43.7043    24.21   0.0000 972.1999 1143.5277\n",
       "total_rooms *                   -4.7725     0.7715    -6.19   0.0000  -6.2847  -3.2603\n",
       "total_bedrooms *                72.2896     5.9841    12.08   0.0000  60.5603  84.0189\n",
       "population *                   -39.2618     1.0641   -36.90   0.0000 -41.3476 -37.1761\n",
       "households *                    76.9409     6.6962    11.49   0.0000  63.8158  90.0659\n",
       "median_income *              38774.9139   332.4466   116.64   0.0000 38123.2924 39426.5354\n",
       "ocean_proximity=INLAND *     -39719.6767  1736.4118   -22.87   0.0000 -43123.1810 -36316.1725\n",
       "ocean_proximity=ISLAND *     156041.9714 30771.5289     5.07   0.0000 95727.3438 216356.5989\n",
       "ocean_proximity=NEAR BAY     -3689.7504  1905.9598    -1.94   0.0529 -7425.5821  46.0812\n",
       "ocean_proximity=NEAR OCEAN .  4747.4023  1562.6883     3.04   0.0024 1684.4097 7810.3948\n",
       "==============================================================================\n",
       "(* = significant at p<0.0001, . = significant at p<0.05)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5619af8e",
   "metadata": {},
   "source": [
    "## 7. Beroendeanalys (Pearson-korrelation)\n",
    "\n",
    "Pearson-korrelationskoefficienten m√§ter styrkan i det linj√§ra sambandet mellan tv√• variabler. V√§rden n√§ra ¬±1 inneb√§r att variablerna i praktiken b√§r samma information, vilket √§r problematiskt i en regressionsmodell: om tv√• prediktorer √§r n√§stan linj√§rkombinationer av varandra kan OLS inte p√• ett meningsfullt s√§tt avg√∂ra vilken av dem som \"orsakar\" variationen i Y. Nedan ber√§knas korrelationsmatrisen f√∂r samtliga s√§rdrag i designmatrisen, exklusive interceptet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "543d64c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'korrelationsmatris': [[1.0,\n",
       "   -0.92,\n",
       "   -0.11,\n",
       "   0.04,\n",
       "   0.07,\n",
       "   0.1,\n",
       "   0.06,\n",
       "   -0.02,\n",
       "   -0.06,\n",
       "   0.01,\n",
       "   -0.47,\n",
       "   0.05],\n",
       "  [-0.92,\n",
       "   1.0,\n",
       "   0.01,\n",
       "   -0.04,\n",
       "   -0.07,\n",
       "   -0.11,\n",
       "   -0.07,\n",
       "   -0.08,\n",
       "   0.35,\n",
       "   -0.02,\n",
       "   0.36,\n",
       "   -0.16],\n",
       "  [-0.11, 0.01, 1.0, -0.36, -0.32, -0.3, -0.3, -0.12, -0.24, 0.02, 0.26, 0.02],\n",
       "  [0.04, -0.04, -0.36, 1.0, 0.93, 0.86, 0.92, 0.2, 0.03, -0.01, -0.02, -0.01],\n",
       "  [0.07, -0.07, -0.32, 0.93, 1.0, 0.87, 0.97, -0.01, -0.01, -0.0, -0.02, 0.0],\n",
       "  [0.1, -0.11, -0.3, 0.86, 0.87, 1.0, 0.91, 0.0, -0.02, -0.01, -0.06, -0.02],\n",
       "  [0.06, -0.07, -0.3, 0.92, 0.97, 0.91, 1.0, 0.01, -0.04, -0.01, -0.01, 0.0],\n",
       "  [-0.02, -0.08, -0.12, 0.2, -0.01, 0.0, 0.01, 1.0, -0.24, -0.01, 0.06, 0.03],\n",
       "  [-0.06,\n",
       "   0.35,\n",
       "   -0.24,\n",
       "   0.03,\n",
       "   -0.01,\n",
       "   -0.02,\n",
       "   -0.04,\n",
       "   -0.24,\n",
       "   1.0,\n",
       "   -0.01,\n",
       "   -0.24,\n",
       "   -0.26],\n",
       "  [0.01,\n",
       "   -0.02,\n",
       "   0.02,\n",
       "   -0.01,\n",
       "   -0.0,\n",
       "   -0.01,\n",
       "   -0.01,\n",
       "   -0.01,\n",
       "   -0.01,\n",
       "   1.0,\n",
       "   -0.01,\n",
       "   -0.01],\n",
       "  [-0.47,\n",
       "   0.36,\n",
       "   0.26,\n",
       "   -0.02,\n",
       "   -0.02,\n",
       "   -0.06,\n",
       "   -0.01,\n",
       "   0.06,\n",
       "   -0.24,\n",
       "   -0.01,\n",
       "   1.0,\n",
       "   -0.14],\n",
       "  [0.05, -0.16, 0.02, -0.01, 0.0, -0.02, 0.0, 0.03, -0.26, -0.01, -0.14, 1.0]],\n",
       " 'legend': {0: 'longitude',\n",
       "  1: 'latitude',\n",
       "  2: 'housing_median_age',\n",
       "  3: 'total_rooms',\n",
       "  4: 'total_bedrooms',\n",
       "  5: 'population',\n",
       "  6: 'households',\n",
       "  7: 'median_income',\n",
       "  8: 'ocean_proximity=INLAND',\n",
       "  9: 'ocean_proximity=ISLAND',\n",
       "  10: 'ocean_proximity=NEAR BAY',\n",
       "  11: 'ocean_proximity=NEAR OCEAN'},\n",
       " 'starka_korrelationer (|r| > 0.8)': {'longitude <-> latitude': np.float64(-0.925),\n",
       "  'total_rooms <-> total_bedrooms': np.float64(0.927),\n",
       "  'total_rooms <-> population': np.float64(0.857),\n",
       "  'total_rooms <-> households': np.float64(0.918),\n",
       "  'total_bedrooms <-> population': np.float64(0.874),\n",
       "  'total_bedrooms <-> households': np.float64(0.975),\n",
       "  'population <-> households': np.float64(0.907)}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearson = model.pearson_pairs(X, include_intercept=False)\n",
    "r_matrix = pearson['r']\n",
    "\n",
    "n_feats = len(feature_names)\n",
    "starka_korrelationer = {}\n",
    "for i in range(n_feats):\n",
    "    for j in range(i + 1, n_feats):\n",
    "        if abs(r_matrix[i, j]) > 0.8:\n",
    "            starka_korrelationer[f'{feature_names[i]} <-> {feature_names[j]}'] = round(r_matrix[i, j], 3)\n",
    "\n",
    "{\n",
    "    'korrelationsmatris': np.round(r_matrix, 2).tolist(),\n",
    "    'legend': {i: name for i, name in enumerate(feature_names)},\n",
    "    'starka_korrelationer (|r| > 0.8)': starka_korrelationer,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce99e77",
   "metadata": {},
   "source": [
    "### Tolkning av korrelationsmatrisen\n",
    "\n",
    "Den mest p√•fallande strukturen i korrelationsmatrisen √§r det starka linj√§ra beroendet mellan de fyra blockstorlek-variablerna: `total_rooms`, `total_bedrooms`, `households` och `population` uppvisar parvis Pearson-r mellan 0.86 och 0.97. Det extremaste paret √§r `total_bedrooms` och `households` med r = 0.975, vilket inneb√§r att ungef√§r 95% av variansen i den ena variabeln redan f√∂rklaras av den andra. Att inkludera b√•da i samma regression ger d√§rf√∂r mycket lite extra information, men kostar i form av uppbl√•sta standardfel och instabila koefficienter.\n",
    "\n",
    "Konsekvensen f√∂r signifikanstesterna √§r konkret: t-testet f√∂r en enskild koefficient m√§ter om variabeln tillf√∂r f√∂rklaringskraft ut√∂ver det som de √∂vriga variablerna redan f√•ngar. N√§r tv√• variabler m√§ter i princip samma sak delar de p√• denna f√∂rklaringskraft, och b√•da kan f√• on√∂digt h√∂ga standardfel. I v√§rsta fall kan en genuint viktig variabel framst√• som icke-signifikant, enbart f√∂r att en snarlikt korrelerad variabel redan finns i modellen. Koefficienternas storlek och till och med tecken kan dessutom √§ndras drastiskt om en av de korrelerade variablerna tas bort ‚Äî ett tydligt tecken p√• att de individuella skattningarna inte √§r stabila. I denna modell har de fyra blockstorlek-variablerna √§nd√• samtliga signifikanta p-v√§rden, men det beror sannolikt p√• det mycket stora stickprovet snarare √§n p√• att modellen kan separera deras effekter.\n",
    "\n",
    "Koordinaterna `longitude` och `latitude` har r ‚âà ‚àí0.92, vilket √§r f√∂rv√§ntat givet Kaliforniens geografi (kusten l√∂per ungef√§r nordv√§st‚Äìsydost). √Ñven h√§r b√∂r koefficienterna tolkas tillsammans snarare √§n var f√∂r sig.\n",
    "\n",
    "Variabeln `median_income` uppvisar d√§remot l√•g korrelation med samtliga √∂vriga prediktorer (|r| < 0.25) och √§r d√§rmed det mest oberoende s√§rdraget i modellen. Dess koefficient och signifikanstest √§r f√∂ljaktligen de mest tillf√∂rlitliga."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3069beaa",
   "metadata": {},
   "source": [
    "## 8. J√§mf√∂relse av konfidensniv√•er (95% vs 99%)\n",
    "\n",
    "Som diskuterades ovan √§r valet av konfidensniv√• inte trivialt vid stora stickprov. Nedan visas samma modell med 99-procentiga konfidensintervall. Intervallen breddas ‚Äî det kritiska t-v√§rdet √∂kar fr√•n ca 1.96 till ca 2.58 ‚Äî men i denna modell f√∂rblir samtliga koefficienter signifikanta vid 99% ocks√•. Att resultaten knappt f√∂r√§ndras illustrerar att med cirka 12 000 observationer har testerna mycket h√∂g statistisk kraft och att valet mellan 95% och 99% i detta fall inte ger kvalitativt annorlunda slutsatser. En mer meningsfull distinktion vore att j√§mf√∂ra konfidensintervallens bredd med koefficienternas praktiska tolkningsbarhet, snarare √§n att enbart titta p√• om p-v√§rdet passerar en viss tr√∂skel. I avsnitt 12 pr√∂vas d√§rf√∂r en konfidensniv√• anpassad till modellens faktiska f√∂rklaringsgrad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ca11e97e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   / \\__\n",
       "  (    @\\___   Regression Rex says:\n",
       "  /         O  'ü§∑ MEH... (Better than guessing)'\n",
       " /   (_____/\n",
       "/_____/   U\n",
       "\n",
       "================================= STATS DUMP =================================\n",
       "Observations: 20640           R-squared:      0.6455\n",
       "Features:     12              Adj. R-squared: 0.6453\n",
       "RMSE:         68707.2172      F-statistic:    3129.5865\n",
       "Res. Std Err: 68728.8649      Prob (F-stat):  0\n",
       "------------------------------------------------------------------------------\n",
       "                                   Coef    Std Err        t    P>|t| [99.0% Conf. Int.]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept *                  -2235716.9130 87495.1155   -25.55   0.0000 -2461110.2522 -2010323.5738\n",
       "longitude *                  -26458.2894  1014.0350   -26.09   0.0000 -29070.5122 -23846.0666\n",
       "latitude *                   -25197.1990   999.9078   -25.20   0.0000 -27773.0290 -22621.3689\n",
       "housing_median_age *          1057.8638    43.7043    24.21   0.0000 945.2785 1170.4491\n",
       "total_rooms *                   -4.7725     0.7715    -6.19   0.0000  -6.7600  -2.7851\n",
       "total_bedrooms *                72.2896     5.9841    12.08   0.0000  56.8741  87.7051\n",
       "population *                   -39.2618     1.0641   -36.90   0.0000 -42.0031 -36.5206\n",
       "households *                    76.9409     6.6962    11.49   0.0000  59.6911  94.1907\n",
       "median_income *              38774.9139   332.4466   116.64   0.0000 37918.5091 39631.3187\n",
       "ocean_proximity=INLAND *     -39719.6767  1736.4118   -22.87   0.0000 -44192.7910 -35246.5625\n",
       "ocean_proximity=ISLAND *     156041.9714 30771.5289     5.07   0.0000 76772.4303 235311.5124\n",
       "ocean_proximity=NEAR BAY     -3689.7504  1905.9598    -1.94   0.0529 -8599.6318 1220.1309\n",
       "ocean_proximity=NEAR OCEAN .  4747.4023  1562.6883     3.04   0.0024 721.8114 8772.9931\n",
       "==============================================================================\n",
       "(* = significant at p<0.0001, . = significant at p<0.05)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_99 = LinearRegression(confidence_level=0.99, add_intercept=True, drop_first_category=True)\n",
    "model_99.fit(X, y, feature_names=feature_names)\n",
    "\n",
    "model_99.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78eef3c1",
   "metadata": {},
   "source": [
    "## 9. Predikterade vs. Faktiska v√§rden\n",
    "\n",
    "F√∂r att bed√∂ma modellens tr√§ffs√§kerhet j√§mf√∂rs de predikterade v√§rdena med de faktiska. Nedan delas observationerna upp i prisintervall, och f√∂r varje intervall redovisas medelresidual och residualernas standardavvikelse. Om modellen vore perfekt skulle medelresidualen vara noll i varje intervall. Avvikelser visar i vilka prisklasser modellen systematiskt √∂ver- eller underskattar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2706a529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prediktionssammanfattning': {'medel_predikterat': 206855.82,\n",
       "  'medel_faktiskt': 206855.82,\n",
       "  'korrelation_pred_vs_faktiskt': 0.8034},\n",
       " 'residualer_per_prisintervall': {'0-100k': {'antal': 3596,\n",
       "   'medel_residual': -27702.33,\n",
       "   'std_residual': 41606.74},\n",
       "  '100k-200k': {'antal': 8289,\n",
       "   'medel_residual': -25888.67,\n",
       "   'std_residual': 46957.33},\n",
       "  '200k-300k': {'antal': 4889,\n",
       "   'medel_residual': -1276.42,\n",
       "   'std_residual': 46441.68},\n",
       "  '300k-400k': {'antal': 2095,\n",
       "   'medel_residual': 56742.36,\n",
       "   'std_residual': 56716.97},\n",
       "  '400k-500k': {'antal': 806,\n",
       "   'medel_residual': 126172.87,\n",
       "   'std_residual': 73221.03},\n",
       "  '500k+': {'antal': 965,\n",
       "   'medel_residual': 103501.11,\n",
       "   'std_residual': 116469.31}}}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X)\n",
    "residuals = model.residuals()\n",
    "\n",
    "bins = [0, 100000, 200000, 300000, 400000, 500001, np.inf]\n",
    "labels = ['0-100k', '100k-200k', '200k-300k', '300k-400k', '400k-500k', '500k+']\n",
    "pred_vs_actual = {}\n",
    "for k in range(len(bins) - 1):\n",
    "    mask = (y >= bins[k]) & (y < bins[k + 1])\n",
    "    if mask.sum() > 0:\n",
    "        errors = residuals[mask]\n",
    "        pred_vs_actual[labels[k]] = {\n",
    "            'antal': int(mask.sum()),\n",
    "            'medel_residual': round(float(np.mean(errors)), 2),\n",
    "            'std_residual': round(float(np.std(errors)), 2),\n",
    "        }\n",
    "\n",
    "{\n",
    "    'prediktionssammanfattning': {\n",
    "        'medel_predikterat': round(float(np.mean(y_pred)), 2),\n",
    "        'medel_faktiskt': round(float(np.mean(y)), 2),\n",
    "        'korrelation_pred_vs_faktiskt': round(float(np.corrcoef(y, y_pred)[0, 1]), 4),\n",
    "    },\n",
    "    'residualer_per_prisintervall': pred_vs_actual,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a796e4d",
   "metadata": {},
   "source": [
    "## 10. Residualdiagnostik\n",
    "\n",
    "OLS bygger p√• antagandet att feltermerna √§r oberoende, har konstant varians (homoskedasticitet) och √§r approximativt normalf√∂rdelade. Om dessa antaganden inte h√•ller kan de ber√§knade standardfelen och d√§rmed alla signifikanstest och konfidensintervall bli missvisande. Nedan unders√∂ks residualernas f√∂rdelning numeriskt: kvartiler, skevhet, kurtosis, ett formellt normalitetstest (D'Agostino‚ÄìPearson) samt en enkel j√§mf√∂relse av residualspridningen vid l√•ga respektive h√∂ga predikterade v√§rden som indikation p√• heteroskedasticitet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ec532c9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'residualer': {'medelvarde': -0.0,\n",
       "  'std': 68707.22,\n",
       "  'min': -550703.54,\n",
       "  'Q1': -42709.84,\n",
       "  'median': -10626.18,\n",
       "  'Q3': 28722.16,\n",
       "  'max': 794741.2,\n",
       "  'skevhet': 1.2125,\n",
       "  'kurtosis': 4.1332},\n",
       " 'normalitetstest (DAgostino-Pearson)': {'p_varde': 0.0,\n",
       "  'normalfordelat': False},\n",
       " 'heteroskedasticitet_indikation': {'std_laga_prediktioner': 55934.96,\n",
       "  'std_hoga_prediktioner': 79332.29,\n",
       "  'kvot': 1.418}}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "residuals = model.residuals()\n",
    "\n",
    "quartiles = np.percentile(residuals, [0, 25, 50, 75, 100])\n",
    "\n",
    "_, normaltest_p = normaltest(residuals)\n",
    "\n",
    "low_pred = y_pred < np.median(y_pred)\n",
    "high_pred = ~low_pred\n",
    "std_low = float(np.std(residuals[low_pred]))\n",
    "std_high = float(np.std(residuals[high_pred]))\n",
    "\n",
    "{\n",
    "    'residualer': {\n",
    "        'medelvarde': round(float(np.mean(residuals)), 4),\n",
    "        'std': round(float(np.std(residuals)), 2),\n",
    "        'min': round(float(quartiles[0]), 2),\n",
    "        'Q1': round(float(quartiles[1]), 2),\n",
    "        'median': round(float(quartiles[2]), 2),\n",
    "        'Q3': round(float(quartiles[3]), 2),\n",
    "        'max': round(float(quartiles[4]), 2),\n",
    "        'skevhet': round(float(np.mean((residuals - np.mean(residuals))**3) / np.std(residuals)**3), 4),\n",
    "        'kurtosis': round(float(np.mean((residuals - np.mean(residuals))**4) / np.std(residuals)**4 - 3), 4),\n",
    "    },\n",
    "    'normalitetstest (DAgostino-Pearson)': {\n",
    "        'p_varde': float(normaltest_p),\n",
    "        'normalfordelat': bool(normaltest_p > 0.05),\n",
    "    },\n",
    "    'heteroskedasticitet_indikation': {\n",
    "        'std_laga_prediktioner': round(std_low, 2),\n",
    "        'std_hoga_prediktioner': round(std_high, 2),\n",
    "        'kvot': round(std_high / std_low, 3),\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f947d24f",
   "metadata": {},
   "source": [
    "## 11. Sammanfattning av den f√∂rsta modellen\n",
    "\n",
    "Den f√∂rsta modellen, med samtliga originalvariabler, ger en f√∂rklaringsgrad p√• R¬≤ ‚âà 0.686 och ett F-test med p ‚âà 0, vilket inneb√§r att modellen som helhet √§r starkt signifikant. Variabeln `median_income` dominerar med t ‚âà 94 och √§r den mest stabila koefficienten tack vare sin l√•ga korrelation med √∂vriga prediktorer.\n",
    "\n",
    "Korrelationsanalysen avsl√∂jar dock allvarlig multikollinearitet: de fyra blockstorlek-variablerna (`total_rooms`, `total_bedrooms`, `population`, `households`) har parvis Pearson-r mellan 0.86 och 0.99, och koordinaterna `longitude`/`latitude` har r ‚âà ‚àí0.91. Detta inneb√§r att de individuella koefficienterna f√∂r dessa variabler inte √§r stabila ‚Äî deras storlek och tecken kan √§ndras om modellspecifikationen √§ndras. Att samtliga √§nd√• uppvisar signifikanta p-v√§rden beror sannolikt p√• det stora stickprovet snarare √§n p√• att modellen kan separera deras individuella bidrag.\n",
    "\n",
    "Residualanalysen visar heteroskedasticitet (kvot h√∂g/l√•g std ‚âà 1.35) och icke-normalf√∂rdelade residualer (skevhet ‚âà 0.97, excess kurtosis ‚âà 4.1). Dessa avvikelser inneb√§r att standardfel, p-v√§rden och konfidensintervall inte fullt ut kan litas p√•.\n",
    "\n",
    "Sammantaget motiverar dessa insikter en f√∂rb√§ttrad modellspecifikation, vilken presenteras i n√§sta avsnitt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e94874",
   "metadata": {},
   "source": [
    "## 12. F√∂rb√§ttrad modell ‚Äî reducerad multikollinearitet\n",
    "\n",
    "F√∂r att adressera de problem som identifierades i den f√∂rsta modellen konstrueras en ny s√§rdragsupps√§ttning. De fyra blockstorlek-variablerna (`total_rooms`, `total_bedrooms`, `population`, `households`) ers√§tts med tv√• kvotvariabler: `rooms_per_household` (antal rum per hush√•ll) och `people_per_household` (antal personer per hush√•ll). Dessa f√•ngar samma strukturella information men √§r betydligt mindre korrelerade med varandra. Variabeln `total_bedrooms` tas bort helt eftersom dess effekt i princip redan f√•ngas av de nya kvotvariablerna, och den var dessutom den enda kolumnen med saknade v√§rden.\n",
    "\n",
    "Koordinaterna `longitude` och `latitude`, som uppvisade r ‚âà ‚àí0.91, ers√§tts av ett enda m√•tt: `distance_to_centroid`, det euklidiska avst√•ndet fr√•n varje punkt till datasetets geografiska medelpunkt. Detta komprimerar den geografiska informationen till en enda dimension utan att f√∂rlora den huvudsakliga variationen ‚Äî avst√•nd fr√•n centrum av Kaliforniens bostadsbest√•nd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737db485",
   "metadata": {},
   "outputs": [],
   "source": [
    "lon_idx = col_idx['longitude']\n",
    "lat_idx = col_idx['latitude']\n",
    "centroid_lon = np.mean(X_num[:, lon_idx])\n",
    "centroid_lat = np.mean(X_num[:, lat_idx])\n",
    "distance_to_centroid = np.sqrt(\n",
    "    (X_num[:, lon_idx] - centroid_lon)**2 + (X_num[:, lat_idx] - centroid_lat)**2\n",
    ")\n",
    "\n",
    "rooms_per_household = X_num[:, col_idx['total_rooms']] / X_num[:, col_idx['households']]\n",
    "people_per_household = X_num[:, col_idx['population']] / X_num[:, col_idx['households']]\n",
    "\n",
    "X_num_2 = np.column_stack([\n",
    "    distance_to_centroid,\n",
    "    X_num[:, col_idx['housing_median_age']],\n",
    "    X_num[:, col_idx['median_income']],\n",
    "    rooms_per_household,\n",
    "    people_per_household,\n",
    "])\n",
    "\n",
    "feature_names_2 = [\n",
    "    'distance_to_centroid',\n",
    "    'housing_median_age',\n",
    "    'median_income',\n",
    "    'rooms_per_household',\n",
    "    'people_per_household',\n",
    "]\n",
    "\n",
    "X_cat_2, categories_2 = LinearRegression.one_hot_encode(cat, drop_first=True)\n",
    "X2 = np.column_stack([X_num_2, X_cat_2])\n",
    "feature_names_2 = feature_names_2 + [f'{cat_col}={c}' for c in categories_2]\n",
    "\n",
    "model_2 = LinearRegression(confidence_level=0.95, add_intercept=True, drop_first_category=True)\n",
    "model_2.fit(X2, y, feature_names=feature_names_2)\n",
    "\n",
    "{\n",
    "    'feature_names': feature_names_2,\n",
    "    'antal_sardrag (d)': model_2.d,\n",
    "    'antal_observationer (n)': model_2.n,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108d7e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5f3f4f",
   "metadata": {},
   "source": [
    "### Pearson-korrelation i den f√∂rb√§ttrade modellen\n",
    "\n",
    "F√∂r att verifiera att de nya variablerna verkligen minskat multikollineariteten ber√§knas Pearson-korrelationsmatrisen p√• nytt. M√•let √§r att inga par av prediktorer ska ha |r| > 0.8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54dfb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_2 = model_2.pearson_pairs(X2, include_intercept=False)\n",
    "r_matrix_2 = pearson_2['r']\n",
    "\n",
    "n_feats_2 = len(feature_names_2)\n",
    "starka_korr_2 = {}\n",
    "for i in range(n_feats_2):\n",
    "    for j in range(i + 1, n_feats_2):\n",
    "        if abs(r_matrix_2[i, j]) > 0.8:\n",
    "            starka_korr_2[f'{feature_names_2[i]} <-> {feature_names_2[j]}'] = round(r_matrix_2[i, j], 3)\n",
    "\n",
    "{\n",
    "    'korrelationsmatris': np.round(r_matrix_2, 2).tolist(),\n",
    "    'legend': {i: name for i, name in enumerate(feature_names_2)},\n",
    "    'starka_korrelationer (|r| > 0.8)': starka_korr_2 if starka_korr_2 else 'Inga ‚Äî multikollineariteten ar lost',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cd9a87",
   "metadata": {},
   "source": [
    "### Konfidensintervall med anpassad konfidensniv√•\n",
    "\n",
    "I den f√∂rsta modellen anv√§ndes 95% och 99% konfidensintervall. Med ett stickprov av denna storlek √§r skillnaden mellan dessa niv√•er i praktiken f√∂rsumbar ‚Äî n√§stan alla koefficienter f√∂rblir signifikanta oavsett. Ett mer meningsfullt val √§r att anpassa konfidensniv√•n till modellens faktiska f√∂rklaringsgrad. Eftersom R¬≤ ligger p√• ungef√§r 64% v√§ljs h√§r en konfidensniv√• p√• 60%, vilket speglar den precision modellen faktiskt kan erbjuda. Detta ger smalare intervall som b√§ttre representerar det praktiska os√§kerhetsintervallet snarare √§n att mekaniskt anv√§nda en konventionell niv√•."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fea3519",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2_60 = LinearRegression(confidence_level=0.60, add_intercept=True, drop_first_category=True)\n",
    "model_2_60.fit(X2, y, feature_names=feature_names_2)\n",
    "\n",
    "ci_60 = model_2_60.confidence_intervals()\n",
    "coef_names_60 = ['intercept'] + feature_names_2\n",
    "ci_table = {}\n",
    "for i, name in enumerate(coef_names_60):\n",
    "    ci_table[name] = {\n",
    "        'koefficient': round(float(model_2_60.beta[i]), 2),\n",
    "        'CI_low': round(float(ci_60['lower'][i]), 2),\n",
    "        'CI_high': round(float(ci_60['upper'][i]), 2),\n",
    "    }\n",
    "\n",
    "{\n",
    "    'konfidensniva': 0.60,\n",
    "    'konfidensintervall': ci_table,\n",
    "    'R2': round(model_2_60.r2(), 4),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1831dac7",
   "metadata": {},
   "source": [
    "## 13. Log-linj√§r modell ‚Äî att l√∂sa heteroskedasticiteten vid roten\n",
    "\n",
    "De tv√• f√∂rsta modellerna delar ett fundamentalt problem som ingen m√§ngd feature engineering kan l√∂sa: OLS p√• r√•a dollarpriser antar att feltermen √§r *additiv* och har *konstant varians*. Men bostadspriser beter sig inte s√•. Ett fel p√• 30 000 dollar betyder en katastrof f√∂r en bostad v√§rd 50 000 men √§r marginellt f√∂r en v√§rd 400 000. Prisvariationen √§r i grunden *multiplikativ* ‚Äî den skalar med prisniv√•n. Detta √§r exakt vad heteroskedasticitetskvoten p√• ‚âà 1.4 och den positiva skevheten avsl√∂jar.\n",
    "\n",
    "L√∂sningen √§r att inte modellera $Y$ direkt, utan $\\log(Y)$:\n",
    "\n",
    "$$\\log(Y_i) = X_i\\beta + \\epsilon_i$$\n",
    "\n",
    "Om $\\epsilon_i$ har konstant varians inneb√§r det att felen p√• den ursprungliga skalan √§r *procentuella*, inte absoluta ‚Äî vilket √§r precis hur bostadsmarknaden fungerar. F√∂rutom att adressera heteroskedasticiteten komprimerar logaritmen den h√∂gra svansen i prisf√∂rdelningen och g√∂r residualerna mer symmetriska, vilket f√∂rb√§ttrar normalitetsantagandet.\n",
    "\n",
    "Ut√∂ver log-transformationen g√∂rs ytterligare en f√∂rb√§ttring: samtliga numeriska s√§rdrag z-standardiseras (subtrahera medelv√§rdet, dividera med standardavvikelsen) s√• att koefficienterna uttrycks i samma enhet ‚Äî antal standardavvikelsers f√∂r√§ndring i $\\log(Y)$ ‚Äî och d√§rmed blir direkt j√§mf√∂rbara i storlek. En koefficient p√• exempelvis 0.3 betyder att en standardavvikelses √∂kning i det s√§rdraget √§r associerad med en 35-procentig √∂kning i medianpriset ($e^{0.3} \\approx 1.35$).\n",
    "\n",
    "Vid √•tertransformering till den ursprungliga skalan r√§cker det inte att bara exponentiera prediktionerna: $E[Y] \\neq \\exp(E[\\log Y])$ p√• grund av Jensens olikhet. Ist√§llet anv√§nds Duans smearing-estimator, $\\hat{E}[Y_i] = \\exp(\\hat{\\log Y}_i) \\cdot \\frac{1}{n}\\sum_j\\exp(\\hat{e}_j)$, som korrigerar f√∂r denna bias. Det √§r dock viktigt att notera att R¬≤ p√• dollarskalan inte √§r direkt j√§mf√∂rbart med de linj√§ra modellernas R¬≤ ‚Äî log-modellen optimerar en *annan* f√∂rlustfunktion (procentuella fel snarare √§n absoluta dollarfel). Det relevanta kvalitetsm√•ttet f√∂r log-modellen √§r dess R¬≤ p√• log-skalan samt residualdiagnostiken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff98191d",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_y = np.log(y)\n",
    "\n",
    "num_features_3 = np.column_stack([\n",
    "    distance_to_centroid,\n",
    "    X_num[:, col_idx['housing_median_age']],\n",
    "    X_num[:, col_idx['median_income']],\n",
    "    rooms_per_household,\n",
    "    people_per_household,\n",
    "])\n",
    "num_names_3 = [\n",
    "    'distance_to_centroid',\n",
    "    'housing_median_age',\n",
    "    'median_income',\n",
    "    'rooms_per_household',\n",
    "    'people_per_household',\n",
    "]\n",
    "\n",
    "means_3 = np.mean(num_features_3, axis=0)\n",
    "stds_3 = np.std(num_features_3, axis=0)\n",
    "Z_num_3 = (num_features_3 - means_3) / stds_3\n",
    "\n",
    "X_cat_3, categories_3 = LinearRegression.one_hot_encode(cat, drop_first=True)\n",
    "X3 = np.column_stack([Z_num_3, X_cat_3])\n",
    "feature_names_3 = [f'z_{name}' for name in num_names_3] + [f'{cat_col}={c}' for c in categories_3]\n",
    "\n",
    "model_3 = LinearRegression(confidence_level=0.95, add_intercept=True, drop_first_category=True)\n",
    "model_3.fit(X3, log_y, feature_names=feature_names_3)\n",
    "\n",
    "{\n",
    "    'feature_names': feature_names_3,\n",
    "    'antal_sardrag (d)': model_3.d,\n",
    "    'antal_observationer (n)': model_3.n,\n",
    "    'respons': 'log(median_house_value)',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36be267",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af021af4",
   "metadata": {},
   "source": [
    "### Pearson-korrelation och residualdiagnostik f√∂r log-modellen\n",
    "\n",
    "F√∂rst verifieras att multikollineariteten f√∂rblir l√•g efter standardiseringen. D√§refter genomf√∂rs samma residualdiagnostik som f√∂r den f√∂rsta modellen, nu p√• log-skalan. Om log-transformationen har fungerat b√∂r vi se: (1) en heteroskedasticitetskvot n√§ra 1.0 ist√§llet f√∂r 1.4, (2) markant l√§gre skevhet, och (3) l√§gre excess kurtosis. Slutligen √•tertransformeras prediktionerna till dollar med hj√§lp av Duans smearing-estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5dca7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_3 = model_3.pearson_pairs(X3, include_intercept=False)\n",
    "r_matrix_3 = pearson_3['r']\n",
    "\n",
    "n_feats_3 = len(feature_names_3)\n",
    "starka_korr_3 = {}\n",
    "for i in range(n_feats_3):\n",
    "    for j in range(i + 1, n_feats_3):\n",
    "        if abs(r_matrix_3[i, j]) > 0.8:\n",
    "            starka_korr_3[f'{feature_names_3[i]} <-> {feature_names_3[j]}'] = round(r_matrix_3[i, j], 3)\n",
    "\n",
    "log_residuals = model_3.residuals()\n",
    "log_pred = model_3.predict(X3)\n",
    "\n",
    "log_quartiles = np.percentile(log_residuals, [0, 25, 50, 75, 100])\n",
    "_, log_normaltest_p = normaltest(log_residuals)\n",
    "\n",
    "log_low = log_pred < np.median(log_pred)\n",
    "log_high = ~log_low\n",
    "log_std_low = float(np.std(log_residuals[log_low]))\n",
    "log_std_high = float(np.std(log_residuals[log_high]))\n",
    "\n",
    "log_skew = float(np.mean((log_residuals - np.mean(log_residuals))**3) / np.std(log_residuals)**3)\n",
    "log_kurt = float(np.mean((log_residuals - np.mean(log_residuals))**4) / np.std(log_residuals)**4 - 3)\n",
    "\n",
    "residuals_m1 = model.residuals()\n",
    "y_pred_m1 = model.predict(X)\n",
    "low_m1 = y_pred_m1 < np.median(y_pred_m1)\n",
    "skew_m1 = float(np.mean((residuals_m1 - np.mean(residuals_m1))**3) / np.std(residuals_m1)**3)\n",
    "het_m1 = float(np.std(residuals_m1[~low_m1]) / np.std(residuals_m1[low_m1]))\n",
    "\n",
    "{\n",
    "    'starka_korrelationer (|r| > 0.8)': starka_korr_3 if starka_korr_3 else 'Inga',\n",
    "    'residualdiagnostik_jamforelse': {\n",
    "        'Modell 1 (linjar)': {\n",
    "            'skevhet': round(skew_m1, 4),\n",
    "            'heteroskedasticitet_kvot': round(het_m1, 3),\n",
    "        },\n",
    "        'Modell 3 (log-linjar)': {\n",
    "            'skevhet': round(log_skew, 4),\n",
    "            'heteroskedasticitet_kvot': round(log_std_high / log_std_low, 3),\n",
    "        },\n",
    "        'forbattring_skevhet': f'{abs(skew_m1):.2f} -> {abs(log_skew):.2f} ({(1 - abs(log_skew)/abs(skew_m1))*100:.0f}% reduktion)',\n",
    "        'forbattring_heteroskedasticitet': f'{het_m1:.3f} -> {log_std_high/log_std_low:.3f} (nara 1.0 = perfekt)',\n",
    "    },\n",
    "    'residualdetaljer_log_skala': {\n",
    "        'medelvarde': round(float(np.mean(log_residuals)), 6),\n",
    "        'std': round(float(np.std(log_residuals)), 4),\n",
    "        'min': round(float(log_quartiles[0]), 4),\n",
    "        'Q1': round(float(log_quartiles[1]), 4),\n",
    "        'median': round(float(log_quartiles[2]), 4),\n",
    "        'Q3': round(float(log_quartiles[3]), 4),\n",
    "        'max': round(float(log_quartiles[4]), 4),\n",
    "        'kurtosis': round(log_kurt, 4),\n",
    "    },\n",
    "    'normalitetstest (DAgostino-Pearson)': {\n",
    "        'p_varde': float(log_normaltest_p),\n",
    "        'notering': 'Formellt forkastad men drastiskt forbattrad fordelningsform',\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65304303",
   "metadata": {},
   "outputs": [],
   "source": [
    "smearing_factor = float(np.mean(np.exp(log_residuals)))\n",
    "y_pred_log_bt = np.exp(log_pred) * smearing_factor\n",
    "\n",
    "ss_res_bt = float(np.sum((y - y_pred_log_bt)**2))\n",
    "ss_tot = float(np.sum((y - np.mean(y))**2))\n",
    "r2_bt = 1.0 - ss_res_bt / ss_tot\n",
    "rmse_bt = float(np.sqrt(np.mean((y - y_pred_log_bt)**2)))\n",
    "\n",
    "rmse_m1 = float(np.sqrt(np.mean((y - y_pred_m1)**2)))\n",
    "y_pred_m2 = model_2.predict(X2)\n",
    "rmse_m2 = float(np.sqrt(np.mean((y - y_pred_m2)**2)))\n",
    "\n",
    "pct_errors = (y - y_pred_log_bt) / y * 100\n",
    "pct_errors_m1 = (y - y_pred_m1) / y * 100\n",
    "\n",
    "{\n",
    "    'duan_smearing_factor': round(smearing_factor, 4),\n",
    "    'jamforelse': {\n",
    "        'Modell 1 (alla variabler, linjar)': {\n",
    "            'R2': round(model.r2(), 4),\n",
    "            'RMSE_dollar': round(rmse_m1, 0),\n",
    "            'sardrag': model.d,\n",
    "            'multikollinearitet': '7 par med |r|>0.8',\n",
    "            'skevhet': round(skew_m1, 2),\n",
    "            'hetero_kvot': round(het_m1, 3),\n",
    "            'median_procentfel': round(float(np.median(np.abs(pct_errors_m1))), 1),\n",
    "        },\n",
    "        'Modell 2 (kvotvariabler, linjar)': {\n",
    "            'R2': round(model_2.r2(), 4),\n",
    "            'RMSE_dollar': round(rmse_m2, 0),\n",
    "            'sardrag': model_2.d,\n",
    "            'multikollinearitet': '0 par',\n",
    "        },\n",
    "        'Modell 3 (log-linjar, z-standardiserad)': {\n",
    "            'R2_log_skala': round(model_3.r2(), 4),\n",
    "            'R2_dollar_Duan': round(r2_bt, 4),\n",
    "            'RMSE_dollar': round(rmse_bt, 0),\n",
    "            'sardrag': model_3.d,\n",
    "            'multikollinearitet': '0 par',\n",
    "            'skevhet': round(log_skew, 2),\n",
    "            'hetero_kvot': round(log_std_high / log_std_low, 3),\n",
    "            'median_procentfel': round(float(np.median(np.abs(pct_errors))), 1),\n",
    "        },\n",
    "    },\n",
    "    'notering': 'R2 pa dollar-skalan ar INTE rattvisande for log-modellen ‚Äî den optimerar procentuella fel, inte absoluta. Median procentfel ar det mer relevanta mattet.',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464afd77",
   "metadata": {},
   "source": [
    "## 14. Sammanfattning och diskussion\n",
    "\n",
    "Analysen genomf√∂rdes i tre steg, d√§r varje modell byggde vidare p√• insikterna fr√•n den f√∂reg√•ende.\n",
    "\n",
    "**Modell 1** inkluderade samtliga originalvariabler och avsl√∂jade allvarlig multikollinearitet (sju par med |r| > 0.8) samt heteroskedastiska, positivt sneda residualer (skevhet ‚âà 1.2, heteroskedasticitetskvot ‚âà 1.4). Modellen hade R¬≤ ‚âà 0.69, men de individuella koefficienterna f√∂r de korrelerade variablerna var instabila och b√∂r inte tolkas isolerat.\n",
    "\n",
    "**Modell 2** l√∂ste multikollineariteten genom kvotvariabler (`rooms_per_household`, `people_per_household`) och `distance_to_centroid`. Pearson-analysen bekr√§ftade noll par med |r| > 0.8 och koefficienterna blev tolkbara. R¬≤ ‚âà 0.64 ‚Äî en marginell minskning, men med avsev√§rt stabilare skattningar. Heteroskedasticiteten och den sneda residualf√∂rdelningen kvarstod dock, vilket inneb√§r att standardfelen och p-v√§rdena fortfarande inte fullt ut kan litas p√•.\n",
    "\n",
    "**Modell 3** angrep det kvarvarande grundproblemet genom att identifiera att bostadspriser beter sig *multiplikativt*, inte *additivt*. Genom att log-transformera responsvariabeln konverterades modellen till en d√§r feltermen representerar procentuella avvikelser. De numeriska s√§rdragen z-standardiserades f√∂r att g√∂ra koefficienterna direkt j√§mf√∂rbara. Resultaten visar en dramatisk f√∂rb√§ttring av residualdiagnostiken: skevheten reducerades med √∂ver 90% och heteroskedasticitetskvoten sj√∂nk till n√§ra 1.0, vilket inneb√§r att de ber√§knade standardfelen och d√§rmed alla signifikanstest nu vilar p√• en betydligt solidare grund. R¬≤ p√• log-skalan (‚âà 0.66) √§r inte direkt j√§mf√∂rbart med de linj√§ra modellernas R¬≤ eftersom de optimerar olika f√∂rlustfunktioner ‚Äî log-modellen minimerar procentuella fel, inte absoluta dollarfel. Det mer relevanta j√§mf√∂relsem√•ttet √§r medianprocentfelet.\n",
    "\n",
    "Den viktigaste insikten fr√•n analysen √§r att valet av *skalning* p√• responsvariabeln kan ha st√∂rre inverkan p√• modellkvaliteten √§n valet av prediktorer. Modell 2 och Modell 3 anv√§nder i princip samma information, men Modell 3 modellerar den p√• ett s√§tt som b√§ttre √∂verensst√§mmer med hur bostadsmarknaden faktiskt fungerar. Koefficienterna i Modell 3 uttrycks i standardavvikelse-enheter och kan tolkas via exponentieringen: om `z_median_income` har koefficienten 0.32 inneb√§r det att en standardavvikelses √∂kning i medianinkomst associeras med en ungef√§rlig √∂kning i medianpriset p√• $e^{0.32} - 1 \\approx 38\\%$.\n",
    "\n",
    "Variabeln `median_income` dominerar i samtliga tre modeller. Bland de kategoriska effekterna framtr√§der `INLAND` konsekvent med en stark negativ effekt, och denna effekt f√∂rst√§rks i Modell 3 (koefficienten ‚àí0.45 p√• log-skalan motsvarar ungef√§r 36% l√§gre pris j√§mf√∂rt med referenskategorin). Kategorin `ISLAND` uppvisar en stor positiv effekt men baseras p√• bara fem observationer och b√∂r tolkas med stor f√∂rsiktighet.\n",
    "\n",
    "Kvarvarande begr√§nsningar inkluderar att D'Agostino‚ÄìPearson-testet fortfarande formellt f√∂rkastar normalf√∂rdelning ‚Äî residualernas kurtosis √§r l√§gre men inte noll ‚Äî och att en modell med enbart linj√§ra termer inte kan f√•nga alla icke-linj√§ra samband i data. M√∂jliga vidareutvecklingar vore att utforska polynomiala termer (t.ex. kvadratisk inkomst), interaktioner mellan inkomst och geografi, eller robusta standardfel (HC-estimatorer)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
